title,authors,abstract,categories,published,clean_abstract,cluster,cluster_topic
Tokenisation over Bounded Alphabets is Hard,"Violeta Kastreva, Philip Whittington, Dennis Komm, Tiago Pimentel","Recent works have shown that tokenisation is NP-complete. However, these works assume tokenisation is applied to inputs with unboundedly large alphabets -- an unrealistic assumption, given that in practice tokenisers operate over fixed-size alphabets, such as bytes or Unicode characters. We close this gap by analysing tokenisation over bounded $n$-ary alphabets, considering two natural variants: bottom-up tokenisation and direct tokenisation, where we must, respectively, select a sequence of merge operations or a vocabulary whose application optimally compresses a dataset. First, we note that proving hardness results for an $n$-ary alphabet proves the same results for alphabets of any larger size. We then prove that even with binary alphabets, both variants are not only NP-complete, but admit no polynomial-time approximation scheme (unless P=NP). We further show that direct tokenisation remains NP-complete even when applied to unary alphabets. While unary alphabets may not be practically useful, this result establishes that the computational intractability of tokenisation is not an artifact of large alphabets or complex constructions, but a fundamental barrier. Overall, our results explain why practical algorithms such as BPE and UnigramLM are heuristic, and points toward approximation algorithms being an important path going forward for tokenisation research.","cs.CL, cs.DS, cs.LG",2025-11-19 18:59:56+00:00,recent work shown tokenisation npcomplete however work assume tokenisation applied input unboundedly large alphabet unrealistic assumption given practice tokenisers operate fixedsize alphabet byte unicode character close gap analysing tokenisation bounded nary alphabet considering two natural variant bottomup tokenisation direct tokenisation must respectively select sequence merge operation vocabulary whose application optimally compress dataset first note proving hardness result nary alphabet prof result alphabet larger size prove even binary alphabet variant npcomplete admit polynomialtime approximation scheme unless pnp show direct tokenisation remains npcomplete even applied unary alphabet unary alphabet may practically useful result establishes computational intractability tokenisation artifact large alphabet complex construction fundamental barrier overall result explain practical algorithm bpe unigramlm heuristic point toward approximation algorithm important path going forward tokenisation research,5,"tokenisation, tokenisers"
GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization,"Yikun Wang, Zuyan Liu, Ziyi Wang, Pengfei Liu, Han Hu, Yongming Rao","Current research on agentic visual reasoning enables deep multimodal understanding but primarily focuses on image manipulation tools, leaving a gap toward more general-purpose agentic models. In this work, we revisit the geolocalization task, which requires not only nuanced visual grounding but also web search to confirm or refine hypotheses during reasoning. Since existing geolocalization benchmarks fail to meet the need for high-resolution imagery and the localization challenge for deep agentic reasoning, we curate GeoBench, a benchmark that includes photos and panoramas from around the world, along with a subset of satellite images of different cities to rigorously evaluate the geolocalization ability of agentic models. We also propose GeoVista, an agentic model that seamlessly integrates tool invocation within the reasoning loop, including an image-zoom-in tool to magnify regions of interest and a web-search tool to retrieve related web information. We develop a complete training pipeline for it, including a cold-start supervised fine-tuning (SFT) stage to learn reasoning patterns and tool-use priors, followed by a reinforcement learning (RL) stage to further enhance reasoning ability. We adopt a hierarchical reward to leverage multi-level geographical information and improve overall geolocalization performance. Experimental results show that GeoVista surpasses other open-source agentic models on the geolocalization task greatly and achieves performance comparable to closed-source models such as Gemini-2.5-flash and GPT-5 on most metrics.",cs.CV,2025-11-19 18:59:22+00:00,current research agentic visual reasoning enables deep multimodal understanding primarily focus image manipulation tool leaving gap toward generalpurpose agentic model work revisit geolocalization task requires nuanced visual grounding also web search confirm refine hypothesis reasoning since existing geolocalization benchmark fail meet need highresolution imagery localization challenge deep agentic reasoning curate geobench benchmark includes photo panorama around world along subset satellite image different city rigorously evaluate geolocalization ability agentic model also propose geovista agentic model seamlessly integrates tool invocation within reasoning loop including imagezoomin tool magnify region interest websearch tool retrieve related web information develop complete training pipeline including coldstart supervised finetuning sft stage learn reasoning pattern tooluse prior followed reinforcement learning rl stage enhance reasoning ability adopt hierarchical reward leverage multilevel geographical information improve overall geolocalization performance experimental result show geovista surpasses opensource agentic model geolocalization task greatly achieves performance comparable closedsource model gemini25flash gpt5 metric,9,"visionlanguageaction, geolocalization"
In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data,"Xiongyi Cai, Ri-Zhao Qiu, Geng Chen, Lai Wei, Isabella Liu, Tianshu Huang, Xuxin Cheng, Xiaolong Wang","Egocentric videos are a valuable and scalable data source to learn manipulation policies. However, due to significant data heterogeneity, most existing approaches utilize human data for simple pre-training, which does not unlock its full potential. This paper first provides a scalable recipe for collecting and using egocentric data by categorizing human data into two categories: in-the-wild and on-task alongside with systematic analysis on how to use the data. We first curate a dataset, PHSD, which contains over 1,000 hours of diverse in-the-wild egocentric data and over 20 hours of on-task data directly aligned to the target manipulation tasks. This enables learning a large egocentric language-conditioned flow matching policy, Human0. With domain adaptation techniques, Human0 minimizes the gap between humans and humanoids. Empirically, we show Human0 achieves several novel properties from scaling human data, including language following of instructions from only human data, few-shot learning, and improved robustness using on-task data. Project website: https://xiongyicai.github.io/In-N-On/","cs.RO, cs.AI, cs.CV",2025-11-19 18:59:04+00:00,egocentric video valuable scalable data source learn manipulation policy however due significant data heterogeneity existing approach utilize human data simple pretraining unlock full potential paper first provides scalable recipe collecting using egocentric data categorizing human data two category inthewild ontask alongside systematic analysis use data first curate dataset phsd contains 1000 hour diverse inthewild egocentric data 20 hour ontask data directly aligned target manipulation task enables learning large egocentric languageconditioned flow matching policy human0 domain adaptation technique human0 minimizes gap human humanoid empirically show human0 achieves several novel property scaling human data including language following instruction human data fewshot learning improved robustness using ontask data project website httpsxiongyicaigithubioinnon,9,"visionlanguageaction, geolocalization"
RescueLens: LLM-Powered Triage and Action on Volunteer Feedback for Food Rescue,"Naveen Raman, Jingwu Tang, Zhiyu Chen, Zheyuan Ryan Shi, Sean Hudson, Ameesh Kapoor, Fei Fang","Food rescue organizations simultaneously tackle food insecurity and waste by working with volunteers to redistribute food from donors who have excess to recipients who need it. Volunteer feedback allows food rescue organizations to identify issues early and ensure volunteer satisfaction. However, food rescue organizations monitor feedback manually, which can be cumbersome and labor-intensive, making it difficult to prioritize which issues are most important. In this work, we investigate how large language models (LLMs) assist food rescue organizers in understanding and taking action based on volunteer experiences. We work with 412 Food Rescue, a large food rescue organization based in Pittsburgh, Pennsylvania, to design RescueLens, an LLM-powered tool that automatically categorizes volunteer feedback, suggests donors and recipients to follow up with, and updates volunteer directions based on feedback. We evaluate the performance of RescueLens on an annotated dataset, and show that it can recover 96% of volunteer issues at 71% precision. Moreover, by ranking donors and recipients according to their rates of volunteer issues, RescueLens allows organizers to focus on 0.5% of donors responsible for more than 30% of volunteer issues. RescueLens is now deployed at 412 Food Rescue and through semi-structured interviews with organizers, we find that RescueLens streamlines the feedback process so organizers better allocate their time.","cs.CY, cs.LG",2025-11-19 18:55:16+00:00,food rescue organization simultaneously tackle food insecurity waste working volunteer redistribute food donor excess recipient need volunteer feedback allows food rescue organization identify issue early ensure volunteer satisfaction however food rescue organization monitor feedback manually cumbersome laborintensive making difficult prioritize issue important work investigate large language model llm assist food rescue organizer understanding taking action based volunteer experience work 412 food rescue large food rescue organization based pittsburgh pennsylvania design rescuelens llmpowered tool automatically categorizes volunteer feedback suggests donor recipient follow update volunteer direction based feedback evaluate performance rescuelens annotated dataset show recover 96 volunteer issue 71 precision moreover ranking donor recipient according rate volunteer issue rescuelens allows organizer focus 05 donor responsible 30 volunteer issue rescuelens deployed 412 food rescue semistructured interview organizer find rescuelens streamlines feedback process organizer better allocate time,1,"rescuelens, volunteer"
The Impact of Quantization on Large Reasoning Model Reinforcement Learning,"Medha Kumar, Zifei Xu, Xin Wang, Tristan Webb","Strong reasoning capabilities can now be achieved by large-scale reinforcement learning (RL) without any supervised fine-tuning. Although post-training quantization (PTQ) and quantization-aware training (QAT) are well studied in the context of fine-tuning, how quantization impacts RL in large reasoning models (LRMs) remains an open question. To answer this question, we conducted systematic experiments and discovered a significant gap in reasoning performance on mathematical benchmarks between post-RL quantized models and their quantization-aware RL optimized counterparts. Our findings suggest that quantization-aware RL training negatively impacted the learning process, whereas PTQ and QLoRA led to greater performance.",cs.LG,2025-11-19 18:50:58+00:00,strong reasoning capability achieved largescale reinforcement learning rl without supervised finetuning although posttraining quantization ptq quantizationaware training qat well studied context finetuning quantization impact rl large reasoning model lrms remains open question answer question conducted systematic experiment discovered significant gap reasoning performance mathematical benchmark postrl quantized model quantizationaware rl optimized counterpart finding suggest quantizationaware rl training negatively impacted learning process whereas ptq qlora led greater performance,6,"qml, higgs"
Hyperspectral Image Classification using Spectral-Spatial Mixer Network,Mohammed Q. Alkhatib,"This paper introduces SS-MixNet, a lightweight and effective deep learning model for hyperspectral image (HSI) classification. The architecture integrates 3D convolutional layers for local spectral-spatial feature extraction with two parallel MLP-style mixer blocks that capture long-range dependencies in spectral and spatial dimensions. A depthwise convolution-based attention mechanism is employed to enhance discriminative capability with minimal computational overhead. The model is evaluated on the QUH-Tangdaowan and QUH-Qingyun datasets using only 1% of labeled data for training and validation. SS-MixNet achieves the highest performance among compared methods, including 2D-CNN, 3D-CNN, IP-SWIN, SimPoolFormer, and HybridKAN, reaching 95.68% and 93.86% overall accuracy on the Tangdaowan and Qingyun datasets, respectively. The results, supported by quantitative metrics and classification maps, confirm the model's effectiveness in delivering accurate and robust predictions with limited supervision. The code will be made publicly available at: https://github.com/mqalkhatib/SS-MixNet",cs.CV,2025-11-19 18:48:52+00:00,paper introduces ssmixnet lightweight effective deep learning model hyperspectral image hsi classification architecture integrates 3d convolutional layer local spectralspatial feature extraction two parallel mlpstyle mixer block capture longrange dependency spectral spatial dimension depthwise convolutionbased attention mechanism employed enhance discriminative capability minimal computational overhead model evaluated quhtangdaowan quhqingyun datasets using 1 labeled data training validation ssmixnet achieves highest performance among compared method including 2dcnn 3dcnn ipswin simpoolformer hybridkan reaching 9568 9386 overall accuracy tangdaowan qingyun datasets respectively result supported quantitative metric classification map confirm model effectiveness delivering accurate robust prediction limited supervision code made publicly available httpsgithubcommqalkhatibssmixnet,8,"cnntransformer, ssmixnet"
Walrus: A Cross-Domain Foundation Model for Continuum Dynamics,"Michael McCabe, Payel Mukhopadhyay, Tanya Marwah, Bruno Regaldo-Saint Blancard, Francois Rozet, Cristiana Diaconu, Lucas Meyer, Kaze W. K. Wong, Hadi Sotoudeh, Alberto Bietti, Irina Espejo, Rio Fear, Siavash Golkar, Tom Hehir, Keiya Hirashima, Geraud Krawezik, Francois Lanusse, Rudy Morel, Ruben Ohana, Liam Parker, Mariel Pettee, Jeff Shen, Kyunghyun Cho, Miles Cranmer, Shirley Ho","Foundation models have transformed machine learning for language and vision, but achieving comparable impact in physical simulation remains a challenge. Data heterogeneity and unstable long-term dynamics inhibit learning from sufficiently diverse dynamics, while varying resolutions and dimensionalities challenge efficient training on modern hardware. Through empirical and theoretical analysis, we incorporate new approaches to mitigate these obstacles, including a harmonic-analysis-based stabilization method, load-balanced distributed 2D and 3D training strategies, and compute-adaptive tokenization. Using these tools, we develop Walrus, a transformer-based foundation model developed primarily for fluid-like continuum dynamics. Walrus is pretrained on nineteen diverse scenarios spanning astrophysics, geoscience, rheology, plasma physics, acoustics, and classical fluids. Experiments show that Walrus outperforms prior foundation models on both short and long term prediction horizons on downstream tasks and across the breadth of pretraining data, while ablation studies confirm the value of our contributions to forecast stability, training throughput, and transfer performance over conventional approaches. Code and weights are released for community use.","cs.LG, cs.AI, cs.CE",2025-11-19 18:36:03+00:00,foundation model transformed machine learning language vision achieving comparable impact physical simulation remains challenge data heterogeneity unstable longterm dynamic inhibit learning sufficiently diverse dynamic varying resolution dimensionality challenge efficient training modern hardware empirical theoretical analysis incorporate new approach mitigate obstacle including harmonicanalysisbased stabilization method loadbalanced distributed 2d 3d training strategy computeadaptive tokenization using tool develop walrus transformerbased foundation model developed primarily fluidlike continuum dynamic walrus pretrained nineteen diverse scenario spanning astrophysics geoscience rheology plasma physic acoustic classical fluid experiment show walrus outperforms prior foundation model short long term prediction horizon downstream task across breadth pretraining data ablation study confirm value contribution forecast stability training throughput transfer performance conventional approach code weight released community use,8,"cnntransformer, ssmixnet"
"Infrastructuring Pop-Up Cities with ""Social Layer"": Designing Serendipitous Co-Livings for Temporary Intentional Communities","Danwen Ji, Botao 'Amber' Hu","After the pandemic, a new form of ""pop-up city"" has emerged -- co-living gatherings of 100-200 people for 4-8 weeks that differ from conferences and hack houses. These temporary intentional communities leverages existing urban infrastructure, blending daily life (housing, meals, care) with self-organized activities like learning, creating, and socializing. They coordinate bottom-up programming through an ""unconference"" system for identity, calendaring, RSVP, and social discovery that fosters spontaneous, serendipitous, enduring ties. This paper examines the design of ""Social Layer,"" an unconferencing system for pop-up cities. We studied its real-world deployment in ShanHaiWoo (Jilin, China, 2023), muChiangmai (Chiangmai, Thailand, 2023), Edge Esmeralda, Edge Esmeralda (Healdsburg, CA, USA, 2024), Aleph (Buenos Aires, Argentina, 2024), and Gathering of Tribe (Lisbon, Portugal, 2024). Our findings distill: (1) the strong concept ""scaffolded spontaneity"" -- infrastructural affordances that balance structure with openness, amplifying participant agency while maintaining privacy and lightweight governance; (2) design implications for design researchers working on pop-up cities.","cs.HC, cs.CY",2025-11-19 18:28:12+00:00,pandemic new form popup city emerged coliving gathering 100200 people 48 week differ conference hack house temporary intentional community leverage existing urban infrastructure blending daily life housing meal care selforganized activity like learning creating socializing coordinate bottomup programming unconference system identity calendaring rsvp social discovery foster spontaneous serendipitous enduring tie paper examines design social layer unconferencing system popup city studied realworld deployment shanhaiwoo jilin china 2023 muchiangmai chiangmai thailand 2023 edge esmeralda edge esmeralda healdsburg ca usa 2024 aleph buenos aire argentina 2024 gathering tribe lisbon portugal 2024 finding distill 1 strong concept scaffolded spontaneity infrastructural affordances balance structure openness amplifying participant agency maintaining privacy lightweight governance 2 design implication design researcher working popup city,1,"rescuelens, volunteer"
Front-door Reducibility: Reducing ADMGs to the Standard Front-door Setting via a Graphical Criterion,"Jianqiao Mao, Max A. Little","Front-door adjustment provides a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow and strict. Although ID algorithm is very useful and is proved effective for causal relation identification in general causal graphs (if it is identifiable), performing ID algorithm does not guarantee to obtain a practical, easy-to-estimate interventional distribution expression. We argue that the applicability of the front-door criterion is not as limited as it seems: many more complicated causal graphs can be reduced to the front-door criterion. In this paper, We introduce front-door reducibility (FDR), a graphical condition on acyclic directed mixed graphs (ADMGs) that extends the applicability of the classic front-door criterion to reduce a large family of complicated causal graphs to a front-door setting by aggregating variables into super-nodes (FDR triple) $\left(\boldsymbol{X}^{*},\boldsymbol{Y}^{*},\boldsymbol{M}^{*}\right)$. After characterizing FDR criterion, we prove a graph-level equivalence between the satisfication of FDR criterion and the applicability of FDR adjustment. Meanwhile, we then present FDR-TID, an exact algorithm that detects an admissible FDR triple, together with established the algorithm's correctness, completeness, and finite termination. Empirically-motivated examples illustrate that many graphs outside the textbook front-door setting are FDR, yielding simple, estimable adjustments where general ID expressions would be cumbersome. FDR thus complements existing identification method by prioritizing interpretability and computational simplicity without sacrificing generality across mixed graphs.","stat.ML, cs.LG",2025-11-19 18:26:55+00:00,frontdoor adjustment provides simple closedform identification formula classical frontdoor criterion applicability often viewed narrow strict although id algorithm useful proved effective causal relation identification general causal graph identifiable performing id algorithm guarantee obtain practical easytoestimate interventional distribution expression argue applicability frontdoor criterion limited seems many complicated causal graph reduced frontdoor criterion paper introduce frontdoor reducibility fdr graphical condition acyclic directed mixed graph admgs extends applicability classic frontdoor criterion reduce large family complicated causal graph frontdoor setting aggregating variable supernodes fdr triple leftboldsymbolxboldsymbolyboldsymbolmright characterizing fdr criterion prove graphlevel equivalence satisfication fdr criterion applicability fdr adjustment meanwhile present fdrtid exact algorithm detects admissible fdr triple together established algorithm correctness completeness finite termination empiricallymotivated example illustrate many graph outside textbook frontdoor setting fdr yielding simple estimable adjustment general id expression would cumbersome fdr thus complement existing identification method prioritizing interpretability computational simplicity without sacrificing generality across mixed graph,5,"tokenisation, tokenisers"
"MF-GCN: A Multi-Frequency Graph Convolutional Network for Tri-Modal Depression Detection Using Eye-Tracking, Facial, and Acoustic Features","Sejuti Rahman, Swakshar Deb, MD. Sameer Iqbal Chowdhury, MD. Jubair Ahmed Sourov, Mohammad Shamsuddin","Eye tracking data quantifies the attentional bias towards negative stimuli that is frequently observed in depressed groups. Audio and video data capture the affective flattening and psychomotor retardation characteristic of depression. Statistical validation confirmed their significant discriminative power in distinguishing depressed from non depressed groups. We address a critical limitation of existing graph-based models that focus on low-frequency information and propose a Multi-Frequency Graph Convolutional Network (MF-GCN). This framework consists of a novel Multi-Frequency Filter Bank Module (MFFBM), which can leverage both low and high frequency signals. Extensive evaluation against traditional machine learning algorithms and deep learning frameworks demonstrates that MF-GCN consistently outperforms baselines. In binary (depressed and non depressed) classification, the model achieved a sensitivity of 0.96 and F2 score of 0.94. For the 3 class (no depression, mild to moderate depression and severe depression) classification task, the proposed method achieved a sensitivity of 0.79 and specificity of 0.87 and siginificantly suprassed other models. To validate generalizability, the model was also evaluated on the Chinese Multimodal Depression Corpus (CMDC) dataset and achieved a sensitivity of 0.95 and F2 score of 0.96. These results confirm that our trimodal, multi frequency framework effectively captures cross modal interaction for accurate depression detection.","cs.CV, cs.AI",2025-11-19 18:18:53+00:00,eye tracking data quantifies attentional bias towards negative stimulus frequently observed depressed group audio video data capture affective flattening psychomotor retardation characteristic depression statistical validation confirmed significant discriminative power distinguishing depressed non depressed group address critical limitation existing graphbased model focus lowfrequency information propose multifrequency graph convolutional network mfgcn framework consists novel multifrequency filter bank module mffbm leverage low high frequency signal extensive evaluation traditional machine learning algorithm deep learning framework demonstrates mfgcn consistently outperforms baseline binary depressed non depressed classification model achieved sensitivity 096 f2 score 094 3 class depression mild moderate depression severe depression classification task proposed method achieved sensitivity 079 specificity 087 siginificantly suprassed model validate generalizability model also evaluated chinese multimodal depression corpus cmdc dataset achieved sensitivity 095 f2 score 096 result confirm trimodal multi frequency framework effectively capture cross modal interaction accurate depression detection,8,"cnntransformer, ssmixnet"
From Qubits to Couplings: A Hybrid Quantum Machine Learning Framework for LHC Physics,"Marwan Ait Haddou, Mohamed Belfkir, Salah Eddine El Harrauss","In this paper, we propose a new Hybrid Quantum Machine Learning (HyQML) framework to improve the sensitivity of double Higgs boson searches in the $HH \to b\bar{b}γγ$ final state at $\sqrt{s}$ = 13.6 TeV. The proposed model combines parameterized quantum circuits with a classical neural network meta-model, enabling event-level features to be embedded in a quantum feature space while maintaining the optimization stability of classical learning. The hybrid model outperforms both a state-of-the-art XGBoost model and a purely quantum implementation by a factor of two, achieving an expected 95% CL upper limit on the non-resonant double Higgs boson production cross-section of $1.9\timesσ_{\text{SM}}$ and $2.1\timesσ_{\text{SM}}$ under background normalization uncertainties of 10% and 50%, respectively. In addition, expected constraints on the Higgs boson self-coupling $κ_λ$ and quartic vector-boson-Higgs coupling $κ_{2V}$ are found to be improved compared to the classical and purely quantum models.","hep-ex, hep-ph",2025-11-19 18:12:05+00:00,paper propose new hybrid quantum machine learning hyqml framework improve sensitivity double higgs boson search hh bbarbγγ final state sqrts 136 tev proposed model combine parameterized quantum circuit classical neural network metamodel enabling eventlevel feature embedded quantum feature space maintaining optimization stability classical learning hybrid model outperforms stateoftheart xgboost model purely quantum implementation factor two achieving expected 95 cl upper limit nonresonant double higgs boson production crosssection 19timesσ_textsm 21timesσ_textsm background normalization uncertainty 10 50 respectively addition expected constraint higgs boson selfcoupling κ_λ quartic vectorbosonhiggs coupling κ_2v found improved compared classical purely quantum model,6,"qml, higgs"
Information Efficiency of Scientific Automation,Mihir Rao,"Scientific discovery can be framed as a thermodynamic process in which an agent invests physical work to acquire information about an environment under a finite work budget. Using established results about the thermodynamics of computing, we derive finite-budget bounds on information gain over rounds of sequential Bayesian learning. We also propose a metric of information-work efficiency, and compare unpartitioned and federated learning strategies under matched work budgets. The presented results offer guidance in the form of bounds and an information efficiency metric for efforts in scientific automation at large.",cs.IT,2025-11-19 18:11:02+00:00,scientific discovery framed thermodynamic process agent invests physical work acquire information environment finite work budget using established result thermodynamics computing derive finitebudget bound information gain round sequential bayesian learning also propose metric informationwork efficiency compare unpartitioned federated learning strategy matched work budget presented result offer guidance form bound information efficiency metric effort scientific automation large,1,"rescuelens, volunteer"
VisPlay: Self-Evolving Vision-Language Models from Images,"Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang","Reinforcement learning (RL) provides a principled framework for improving Vision-Language Models (VLMs) on complex reasoning tasks. However, existing RL approaches often rely on human-annotated labels or task-specific heuristics to define verifiable rewards, both of which are costly and difficult to scale. We introduce VisPlay, a self-evolving RL framework that enables VLMs to autonomously improve their reasoning abilities using large amounts of unlabeled image data. Starting from a single base VLM, VisPlay assigns the model into two interacting roles: an Image-Conditioned Questioner that formulates challenging yet answerable visual questions, and a Multimodal Reasoner that generates silver responses. These roles are jointly trained with Group Relative Policy Optimization (GRPO), which incorporates diversity and difficulty rewards to balance the complexity of generated questions with the quality of the silver answers. VisPlay scales efficiently across two model families. When trained on Qwen2.5-VL and MiMo-VL, VisPlay achieves consistent improvements in visual reasoning, compositional generalization, and hallucination reduction across eight benchmarks, including MM-Vet and MMMU, demonstrating a scalable path toward self-evolving multimodal intelligence. The project page is available at https://bruno686.github.io/VisPlay/","cs.CV, cs.AI, cs.CL, cs.LG",2025-11-19 17:55:15+00:00,reinforcement learning rl provides principled framework improving visionlanguage model vlms complex reasoning task however existing rl approach often rely humanannotated label taskspecific heuristic define verifiable reward costly difficult scale introduce visplay selfevolving rl framework enables vlms autonomously improve reasoning ability using large amount unlabeled image data starting single base vlm visplay assigns model two interacting role imageconditioned questioner formulates challenging yet answerable visual question multimodal reasoner generates silver response role jointly trained group relative policy optimization grpo incorporates diversity difficulty reward balance complexity generated question quality silver answer visplay scale efficiently across two model family trained qwen25vl mimovl visplay achieves consistent improvement visual reasoning compositional generalization hallucination reduction across eight benchmark including mmvet mmmu demonstrating scalable path toward selfevolving multimodal intelligence project page available httpsbruno686githubiovisplay,9,"visionlanguageaction, geolocalization"
Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and Open Challenges,"Kim N. Nolle, Ivana Dusparic, Rhodri Cusack, Vinny Cahill","Continual learning (CL) is a branch of machine learning that aims to enable agents to adapt and generalise previously learned abilities so that these can be reapplied to new tasks or environments. This is particularly useful in multi-task settings or in non-stationary environments, where the dynamics can change over time. This is particularly relevant in cyber-physical systems such as autonomous driving. However, despite recent advances in CL, successfully applying it to reinforcement learning (RL) is still an open problem.
  This paper highlights open challenges in continual RL (CRL) based on experiments in an autonomous driving environment. In this environment, the agent must learn to successfully park in four different scenarios corresponding to parking spaces oriented at varying angles. The agent is successively trained in these four scenarios one after another, representing a CL environment, using Proximal Policy Optimisation (PPO). These experiments exposed a number of open challenges in CRL: finding suitable abstractions of the environment, oversensitivity to hyperparameters, catastrophic forgetting, and efficient use of neural network capacity.
  Based on these identified challenges, we present open research questions that are important to be addressed for creating robust CRL systems. In addition, the identified challenges call into question the suitability of neural networks for CL. We also identify the need for interdisciplinary research, in particular between computer science and neuroscience.","cs.LG, cs.AI",2025-11-19 17:40:13+00:00,continual learning cl branch machine learning aim enable agent adapt generalise previously learned ability reapplied new task environment particularly useful multitask setting nonstationary environment dynamic change time particularly relevant cyberphysical system autonomous driving however despite recent advance cl successfully applying reinforcement learning rl still open problem paper highlight open challenge continual rl crl based experiment autonomous driving environment environment agent must learn successfully park four different scenario corresponding parking space oriented varying angle agent successively trained four scenario one another representing cl environment using proximal policy optimisation ppo experiment exposed number open challenge crl finding suitable abstraction environment oversensitivity hyperparameters catastrophic forgetting efficient use neural network capacity based identified challenge present open research question important addressed creating robust crl system addition identified challenge call question suitability neural network cl also identify need interdisciplinary research particular computer science neuroscience,9,"visionlanguageaction, geolocalization"
Multi-Stage Residual-Aware Unsupervised Deep Learning Framework for Consistent Ultrasound Strain Elastography,"Shourov Joarder, Tushar Talukder Showrav, Md. Kamrul Hasan","Ultrasound Strain Elastography (USE) is a powerful non-invasive imaging technique for assessing tissue mechanical properties, offering crucial diagnostic value across diverse clinical applications. However, its clinical application remains limited by tissue decorrelation noise, scarcity of ground truth, and inconsistent strain estimation under different deformation conditions. Overcoming these barriers, we propose MUSSE-Net, a residual-aware, multi-stage unsupervised sequential deep learning framework designed for robust and consistent strain estimation. At its backbone lies our proposed USSE-Net, an end-to-end multi-stream encoder-decoder architecture that parallelly processes pre- and post-deformation RF sequences to estimate displacement fields and axial strains. The novel architecture incorporates Context-Aware Complementary Feature Fusion (CACFF)-based encoder with Tri-Cross Attention (TCA) bottleneck with a Cross-Attentive Fusion (CAF)-based sequential decoder. To ensure temporal coherence and strain stability across varying deformation levels, this architecture leverages a tailored consistency loss. Finally, with the MUSSE-Net framework, a secondary residual refinement stage further enhances accuracy and suppresses noise. Extensive validation on simulation, in vivo, and private clinical datasets from Bangladesh University of Engineering and Technology (BUET) medical center, demonstrates MUSSE-Net's outperformed existing unsupervised approaches. On MUSSE-Net achieves state-of-the-art performance with a target SNR of 24.54, background SNR of 132.76, CNR of 59.81, and elastographic SNR of 9.73 on simulation data. In particular, on the BUET dataset, MUSSE-Net produces strain maps with enhanced lesion-to-background contrast and significant noise suppression yielding clinically interpretable strain patterns.",cs.CV,2025-11-19 17:22:25+00:00,ultrasound strain elastography use powerful noninvasive imaging technique assessing tissue mechanical property offering crucial diagnostic value across diverse clinical application however clinical application remains limited tissue decorrelation noise scarcity ground truth inconsistent strain estimation different deformation condition overcoming barrier propose mussenet residualaware multistage unsupervised sequential deep learning framework designed robust consistent strain estimation backbone lie proposed ussenet endtoend multistream encoderdecoder architecture parallelly process pre postdeformation rf sequence estimate displacement field axial strain novel architecture incorporates contextaware complementary feature fusion cacffbased encoder tricross attention tca bottleneck crossattentive fusion cafbased sequential decoder ensure temporal coherence strain stability across varying deformation level architecture leverage tailored consistency loss finally mussenet framework secondary residual refinement stage enhances accuracy suppresses noise extensive validation simulation vivo private clinical datasets bangladesh university engineering technology buet medical center demonstrates mussenets outperformed existing unsupervised approach mussenet achieves stateoftheart performance target snr 2454 background snr 13276 cnr 5981 elastographic snr 973 simulation data particular buet dataset mussenet produce strain map enhanced lesiontobackground contrast significant noise suppression yielding clinically interpretable strain pattern,0,"ultrasound, elastography"
Learning from Imperfect Labels: A Physics-Aware Neural Operator with Application to DAS Data Denoising,"Yang Cui, Denis Anikiev, Umair Bin Waheed, Yangkang Chen","Supervised deep learning methods typically require large datasets and high-quality labels to achieve reliable predictions. However, their performance often degrades when trained on imperfect labels. To address this challenge, we propose a physics-aware loss function that serves as a penalty term to mitigate label imperfections during training. In addition, we introduce a modified U-Net-Enhanced Fourier Neural Operator (UFNO) that achieves high-fidelity feature representation while leveraging the advantages of operator learning in function space. By combining these two components, we develop a physics-aware UFNO (PAUFNO) framework that effectively learns from imperfect labels. To evaluate the proposed framework, we apply it to the denoising of distributed acoustic sensing (DAS) data from the Utah FORGE site. The label data were generated using an integrated filtering-based method, but still contain residual coupling noise in the near-wellbore channels. The denoising workflow incorporates a patching-based data augmentation strategy, including an uplifting step, spatial-domain convolutional operations, spectral convolution, and a projection layer to restore data to the desired shape. Extensive numerical experiments demonstrate that the proposed framework achieves superior denoising performance, effectively enhancing DAS records and recovering hidden signals with high accuracy.",physics.geo-ph,2025-11-19 17:21:22+00:00,supervised deep learning method typically require large datasets highquality label achieve reliable prediction however performance often degrades trained imperfect label address challenge propose physicsaware loss function serf penalty term mitigate label imperfection training addition introduce modified unetenhanced fourier neural operator ufno achieves highfidelity feature representation leveraging advantage operator learning function space combining two component develop physicsaware ufno paufno framework effectively learns imperfect label evaluate proposed framework apply denoising distributed acoustic sensing da data utah forge site label data generated using integrated filteringbased method still contain residual coupling noise nearwellbore channel denoising workflow incorporates patchingbased data augmentation strategy including uplifting step spatialdomain convolutional operation spectral convolution projection layer restore data desired shape extensive numerical experiment demonstrate proposed framework achieves superior denoising performance effectively enhancing da record recovering hidden signal high accuracy,7,"supervised, audio"
Rényi Differential Privacy for Heavy-Tailed SDEs via Fractional Poincaré Inequalities,"Benjamin Dupuis, Mert Gürbüzbalaban, Umut Şimşekli, Jian Wang, Sinan Yildirim, Lingjiong Zhu","Characterizing the differential privacy (DP) of learning algorithms has become a major challenge in recent years. In parallel, many studies suggested investigating the behavior of stochastic gradient descent (SGD) with heavy-tailed noise, both as a model for modern deep learning models and to improve their performance. However, most DP bounds focus on light-tailed noise, where satisfactory guarantees have been obtained but the proposed techniques do not directly extend to the heavy-tailed setting. Recently, the first DP guarantees for heavy-tailed SGD were obtained. These results provide $(0,δ)$-DP guarantees without requiring gradient clipping. Despite casting new light on the link between DP and heavy-tailed algorithms, these results have a strong dependence on the number of parameters and cannot be extended to other DP notions like the well-established Rényi differential privacy (RDP). In this work, we propose to address these limitations by deriving the first RDP guarantees for heavy-tailed SDEs, as well as their discretized counterparts. Our framework is based on new Rényi flow computations and the use of well-established fractional Poincaré inequalities. Under the assumption that such inequalities are satisfied, we obtain DP guarantees that have a much weaker dependence on the dimension compared to prior art.","stat.ML, cs.LG",2025-11-19 17:18:54+00:00,characterizing differential privacy dp learning algorithm become major challenge recent year parallel many study suggested investigating behavior stochastic gradient descent sgd heavytailed noise model modern deep learning model improve performance however dp bound focus lighttailed noise satisfactory guarantee obtained proposed technique directly extend heavytailed setting recently first dp guarantee heavytailed sgd obtained result provide 0δdp guarantee without requiring gradient clipping despite casting new light link dp heavytailed algorithm result strong dependence number parameter cannot extended dp notion like wellestablished rényi differential privacy rdp work propose address limitation deriving first rdp guarantee heavytailed sdes well discretized counterpart framework based new rényi flow computation use wellestablished fractional poincaré inequality assumption inequality satisfied obtain dp guarantee much weaker dependence dimension compared prior art,2,"dynamicslearning, sgd"
Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning,"Tao Hu, Lan Li, Zhen-Hao Xie, Da-Wei Zhou","Class-Incremental Learning (CIL) enables models to learn new classes continually while preserving past knowledge. Recently, vision-language models like CLIP offer transferable features via multi-modal pre-training, making them well-suited for CIL. However, real-world visual and linguistic concepts are inherently hierarchical: a textual concept like ""dog"" subsumes fine-grained categories such as ""Labrador"" and ""Golden Retriever,"" and each category entails its images. But existing CLIP-based CIL methods fail to explicitly capture this inherent hierarchy, leading to fine-grained class features drift during incremental updates and ultimately to catastrophic forgetting. To address this challenge, we propose HASTEN (Hierarchical Semantic Tree Anchoring) that anchors hierarchical information into CIL to reduce catastrophic forgetting. First, we employ an external knowledge graph as supervision to embed visual and textual features in hyperbolic space, effectively preserving hierarchical structure as data evolves. Second, to mitigate catastrophic forgetting, we project gradients onto the null space of the shared hyperbolic mapper, preventing interference with prior tasks. These two steps work synergistically to enable the model to resist forgetting by maintaining hierarchical relationships. Extensive experiments show that HASTEN consistently outperforms existing methods while providing a unified structured representation.","cs.CV, cs.LG",2025-11-19 17:14:47+00:00,classincremental learning cil enables model learn new class continually preserving past knowledge recently visionlanguage model like clip offer transferable feature via multimodal pretraining making wellsuited cil however realworld visual linguistic concept inherently hierarchical textual concept like dog subsumes finegrained category labrador golden retriever category entail image existing clipbased cil method fail explicitly capture inherent hierarchy leading finegrained class feature drift incremental update ultimately catastrophic forgetting address challenge propose hasten hierarchical semantic tree anchoring anchor hierarchical information cil reduce catastrophic forgetting first employ external knowledge graph supervision embed visual textual feature hyperbolic space effectively preserving hierarchical structure data evolves second mitigate catastrophic forgetting project gradient onto null space shared hyperbolic mapper preventing interference prior task two step work synergistically enable model resist forgetting maintaining hierarchical relationship extensive experiment show hasten consistently outperforms existing method providing unified structured representation,4,"forgetting, memoryintensive"
CODE-II: A large-scale dataset for artificial intelligence in ECG analysis,"Petrus E. O. G. B. Abreu, Gabriela M. M. Paixão, Jiawei Li, Paulo R. Gomes, Peter W. Macfarlane, Ana C. S. Oliveira, Vinicius T. Carvalho, Thomas B. Schön, Antonio Luiz P. Ribeiro, Antônio H. Ribeiro","Data-driven methods for electrocardiogram (ECG) interpretation are rapidly progressing. Large datasets have enabled advances in artificial intelligence (AI) based ECG analysis, yet limitations in annotation quality, size, and scope remain major challenges. Here we present CODE-II, a large-scale real-world dataset of 2,735,269 12-lead ECGs from 2,093,807 adult patients collected by the Telehealth Network of Minas Gerais (TNMG), Brazil. Each exam was annotated using standardized diagnostic criteria and reviewed by cardiologists. A defining feature of CODE-II is a set of 66 clinically meaningful diagnostic classes, developed with cardiologist input and routinely used in telehealth practice. We additionally provide an open available subset: CODE-II-open, a public subset of 15,000 patients, and the CODE-II-test, a non-overlapping set of 8,475 exams reviewed by multiple cardiologists for blinded evaluation. A neural network pre-trained on CODE-II achieved superior transfer performance on external benchmarks (PTB-XL and CPSC 2018) and outperformed alternatives trained on larger datasets.","eess.SP, cs.LG",2025-11-19 17:14:05+00:00,datadriven method electrocardiogram ecg interpretation rapidly progressing large datasets enabled advance artificial intelligence ai based ecg analysis yet limitation annotation quality size scope remain major challenge present codeii largescale realworld dataset 2735269 12lead ecg 2093807 adult patient collected telehealth network mina gerais tnmg brazil exam annotated using standardized diagnostic criterion reviewed cardiologist defining feature codeii set 66 clinically meaningful diagnostic class developed cardiologist input routinely used telehealth practice additionally provide open available subset codeiiopen public subset 15000 patient codeiitest nonoverlapping set 8475 exam reviewed multiple cardiologist blinded evaluation neural network pretrained codeii achieved superior transfer performance external benchmark ptbxl cpsc 2018 outperformed alternative trained larger datasets,0,"ultrasound, elastography"
Lost in Vagueness: Towards Context-Sensitive Standards for Robustness Assessment under the EU AI Act,"Roberta Tamponi, Carina Prunkl, Thomas Bäck, Anna V. Kononova","Robustness is a key requirement for high-risk AI systems under the EU Artificial Intelligence Act (AI Act). However, both its definition and assessment methods remain underspecified, leaving providers with little concrete direction on how to demonstrate compliance. This stems from the Act's horizontal approach, which establishes general obligations applicable across all AI systems, but leaves the task of providing technical guidance to harmonised standards. This paper investigates what it means for AI systems to be robust and illustrates the need for context-sensitive standardisation. We argue that robustness is not a fixed property of a system, but depends on which aspects of performance are expected to remain stable (""robustness of what""), the perturbations the system must withstand (""robustness to what"") and the operational environment. We identify three contextual drivers--use case, data and model--that shape the relevant perturbations and influence the choice of tests, metrics and benchmarks used to evaluate robustness. The need to provide at least a range of technical options that providers can assess and implement in light of the system's purpose is explicitly recognised by the standardisation request for the AI Act, but planned standards, still focused on horizontal coverage, do not yet offer this level of detail. Building on this, we propose a context-sensitive multi-layered standardisation framework where horizontal standards set common principles and terminology, while domain-specific ones identify risks across the AI lifecycle and guide appropriate practices, organised in a dynamic repository where providers can propose new informative methods and share lessons learned. Such a system reduces the interpretative burden, mitigates arbitrariness and addresses the obsolescence of static standards, ensuring that robustness assessment is both adaptable and operationally meaningful.",cs.CY,2025-11-19 17:06:36+00:00,robustness key requirement highrisk ai system eu artificial intelligence act ai act however definition assessment method remain underspecified leaving provider little concrete direction demonstrate compliance stem act horizontal approach establishes general obligation applicable across ai system leaf task providing technical guidance harmonised standard paper investigates mean ai system robust illustrates need contextsensitive standardisation argue robustness fixed property system depends aspect performance expected remain stable robustness perturbation system must withstand robustness operational environment identify three contextual driversuse case data modelthat shape relevant perturbation influence choice test metric benchmark used evaluate robustness need provide least range technical option provider assess implement light system purpose explicitly recognised standardisation request ai act planned standard still focused horizontal coverage yet offer level detail building propose contextsensitive multilayered standardisation framework horizontal standard set common principle terminology domainspecific one identify risk across ai lifecycle guide appropriate practice organised dynamic repository provider propose new informative method share lesson learned system reduces interpretative burden mitigates arbitrariness address obsolescence static standard ensuring robustness assessment adaptable operationally meaningful,1,"rescuelens, volunteer"
CODE: A global approach to ODE dynamics learning,"Nils Wildt, Daniel M. Tartakovsky, Sergey Oladyshkin, Wolfgang Nowak","Ordinary differential equations (ODEs) are a conventional way to describe the observed dynamics of physical systems. Scientists typically hypothesize about dynamical behavior, propose a mathematical model, and compare its predictions to data. However, modern computing and algorithmic advances now enable purely data-driven learning of governing dynamics directly from observations. In data-driven settings, one learns the ODE's right-hand side (RHS). Dense measurements are often assumed, yet high temporal resolution is typically both cumbersome and expensive. Consequently, one usually has only sparsely sampled data. In this work we introduce ChaosODE (CODE), a Polynomial Chaos ODE Expansion in which we use an arbitrary Polynomial Chaos Expansion (aPCE) for the ODE's right-hand side, resulting in a global orthonormal polynomial representation of dynamics. We evaluate the performance of CODE in several experiments on the Lotka-Volterra system, across varying noise levels, initial conditions, and predictions far into the future, even on previously unseen initial conditions. CODE exhibits remarkable extrapolation capabilities even when evaluated under novel initial conditions and shows advantages compared to well-examined methods using neural networks (NeuralODE) or kernel approximators (KernelODE) as the RHS representer. We observe that the high flexibility of NeuralODE and KernelODE degrades extrapolation capabilities under scarce data and measurement noise. Finally, we provide practical guidelines for robust optimization of dynamics-learning problems and illustrate them in the accompanying code.","cs.LG, stat.ML",2025-11-19 17:04:24+00:00,ordinary differential equation ode conventional way describe observed dynamic physical system scientist typically hypothesize dynamical behavior propose mathematical model compare prediction data however modern computing algorithmic advance enable purely datadriven learning governing dynamic directly observation datadriven setting one learns ode righthand side rh dense measurement often assumed yet high temporal resolution typically cumbersome expensive consequently one usually sparsely sampled data work introduce chaosode code polynomial chaos ode expansion use arbitrary polynomial chaos expansion apce ode righthand side resulting global orthonormal polynomial representation dynamic evaluate performance code several experiment lotkavolterra system across varying noise level initial condition prediction far future even previously unseen initial condition code exhibit remarkable extrapolation capability even evaluated novel initial condition show advantage compared wellexamined method using neural network neuralode kernel approximators kernelode rh representer observe high flexibility neuralode kernelode degrades extrapolation capability scarce data measurement noise finally provide practical guideline robust optimization dynamicslearning problem illustrate accompanying code,2,"dynamicslearning, sgd"
Near-optimal delta-convex estimation of Lipschitz functions,Gábor Balázs,"This paper presents a tractable algorithm for estimating an unknown Lipschitz function from noisy observations and establishes an upper bound on its convergence rate. The approach extends max-affine methods from convex shape-restricted regression to the more general Lipschitz setting. A key component is a nonlinear feature expansion that maps max-affine functions into a subclass of delta-convex functions, which act as universal approximators of Lipschitz functions while preserving their Lipschitz constants. Leveraging this property, the estimator attains the minimax convergence rate (up to logarithmic factors) with respect to the intrinsic dimension of the data under squared loss and subgaussian distributions in the random design setting. The algorithm integrates adaptive partitioning to capture intrinsic dimension, a penalty-based regularization mechanism that removes the need to know the true Lipschitz constant, and a two-stage optimization procedure combining a convex initialization with local refinement. The framework is also straightforward to adapt to convex shape-restricted regression. Experiments demonstrate competitive performance relative to other theoretically justified methods, including nearest-neighbor and kernel-based regressors.","stat.ML, cs.LG",2025-11-19 17:02:30+00:00,paper present tractable algorithm estimating unknown lipschitz function noisy observation establishes upper bound convergence rate approach extends maxaffine method convex shaperestricted regression general lipschitz setting key component nonlinear feature expansion map maxaffine function subclass deltaconvex function act universal approximators lipschitz function preserving lipschitz constant leveraging property estimator attains minimax convergence rate logarithmic factor respect intrinsic dimension data squared loss subgaussian distribution random design setting algorithm integrates adaptive partitioning capture intrinsic dimension penaltybased regularization mechanism remove need know true lipschitz constant twostage optimization procedure combining convex initialization local refinement framework also straightforward adapt convex shaperestricted regression experiment demonstrate competitive performance relative theoretically justified method including nearestneighbor kernelbased regressors,2,"dynamicslearning, sgd"
Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography,"Sai Puppala, Ismail Hossain, Jahangir Alam, Sajedul Talukder","The integration of advanced robotics in nuclear power plants (NPPs) presents a transformative opportunity to enhance safety, efficiency, and environmental monitoring in high-stakes environments. Our paper introduces the Optimus-Q robot, a sophisticated system designed to autonomously monitor air quality and detect contamination while leveraging adaptive learning techniques and secure quantum communication. Equipped with advanced infrared sensors, the Optimus-Q robot continuously streams real-time environmental data to predict hazardous gas emissions, including carbon dioxide (CO$_2$), carbon monoxide (CO), and methane (CH$_4$). Utilizing a federated learning approach, the robot collaborates with other systems across various NPPs to improve its predictive capabilities without compromising data privacy. Additionally, the implementation of Quantum Key Distribution (QKD) ensures secure data transmission, safeguarding sensitive operational information. Our methodology combines systematic navigation patterns with machine learning algorithms to facilitate efficient coverage of designated areas, thereby optimizing contamination monitoring processes. Through simulations and real-world experiments, we demonstrate the effectiveness of the Optimus-Q robot in enhancing operational safety and responsiveness in nuclear facilities. This research underscores the potential of integrating robotics, machine learning, and quantum technologies to revolutionize monitoring systems in hazardous environments.","cs.RO, cs.AI",2025-11-19 17:01:24+00:00,integration advanced robotics nuclear power plant npps present transformative opportunity enhance safety efficiency environmental monitoring highstakes environment paper introduces optimusq robot sophisticated system designed autonomously monitor air quality detect contamination leveraging adaptive learning technique secure quantum communication equipped advanced infrared sensor optimusq robot continuously stream realtime environmental data predict hazardous gas emission including carbon dioxide co_2 carbon monoxide co methane ch_4 utilizing federated learning approach robot collaborates system across various npps improve predictive capability without compromising data privacy additionally implementation quantum key distribution qkd ensures secure data transmission safeguarding sensitive operational information methodology combine systematic navigation pattern machine learning algorithm facilitate efficient coverage designated area thereby optimizing contamination monitoring process simulation realworld experiment demonstrate effectiveness optimusq robot enhancing operational safety responsiveness nuclear facility research underscore potential integrating robotics machine learning quantum technology revolutionize monitoring system hazardous environment,6,"qml, higgs"
SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models,"Senyu Fei, Siyin Wang, Li Ji, Ao Li, Shiduo Zhang, Liming Liu, Jinlong Hou, Jingjing Gong, Xianzhong Zhao, Xipeng Qiu","Vision-Language-Action (VLA) models excel in robotic manipulation but are constrained by their heavy reliance on expert demonstrations, leading to demonstration bias and limiting performance. Reinforcement learning (RL) is a vital post-training strategy to overcome these limits, yet current VLA-RL methods, including group-based optimization approaches, are crippled by severe reward sparsity. Relying on binary success indicators wastes valuable information in failed trajectories, resulting in low training efficiency. To solve this, we propose Self-Referential Policy Optimization (SRPO), a novel VLA-RL framework. SRPO eliminates the need for external demonstrations or manual reward engineering by leveraging the model's own successful trajectories, generated within the current training batch, as a self-reference. This allows us to assign a progress-wise reward to failed attempts. A core innovation is the use of latent world representations to measure behavioral progress robustly. Instead of relying on raw pixels or requiring domain-specific fine-tuning, we utilize the compressed, transferable encodings from a world model's latent space. These representations naturally capture progress patterns across environments, enabling accurate, generalized trajectory comparison. Empirical evaluations on the LIBERO benchmark demonstrate SRPO's efficiency and effectiveness. Starting from a supervised baseline with 48.9% success, SRPO achieves a new state-of-the-art success rate of 99.2% in just 200 RL steps, representing a 103% relative improvement without any extra supervision. Furthermore, SRPO shows substantial robustness, achieving a 167% performance improvement on the LIBERO-Plus benchmark.","cs.RO, cs.CL, cs.CV",2025-11-19 16:52:23+00:00,visionlanguageaction vla model excel robotic manipulation constrained heavy reliance expert demonstration leading demonstration bias limiting performance reinforcement learning rl vital posttraining strategy overcome limit yet current vlarl method including groupbased optimization approach crippled severe reward sparsity relying binary success indicator waste valuable information failed trajectory resulting low training efficiency solve propose selfreferential policy optimization srpo novel vlarl framework srpo eliminates need external demonstration manual reward engineering leveraging model successful trajectory generated within current training batch selfreference allows u assign progresswise reward failed attempt core innovation use latent world representation measure behavioral progress robustly instead relying raw pixel requiring domainspecific finetuning utilize compressed transferable encoding world model latent space representation naturally capture progress pattern across environment enabling accurate generalized trajectory comparison empirical evaluation libero benchmark demonstrate srpos efficiency effectiveness starting supervised baseline 489 success srpo achieves new stateoftheart success rate 992 200 rl step representing 103 relative improvement without extra supervision furthermore srpo show substantial robustness achieving 167 performance improvement liberoplus benchmark,9,"visionlanguageaction, geolocalization"
US-X Complete: A Multi-Modal Approach to Anatomical 3D Shape Recovery,"Miruna-Alexandra Gafencu, Yordanka Velikova, Nassir Navab, Mohammad Farid Azampour","Ultrasound offers a radiation-free, cost-effective solution for real-time visualization of spinal landmarks, paraspinal soft tissues and neurovascular structures, making it valuable for intraoperative guidance during spinal procedures. However, ultrasound suffers from inherent limitations in visualizing complete vertebral anatomy, in particular vertebral bodies, due to acoustic shadowing effects caused by bone. In this work, we present a novel multi-modal deep learning method for completing occluded anatomical structures in 3D ultrasound by leveraging complementary information from a single X-ray image. To enable training, we generate paired training data consisting of: (1) 2D lateral vertebral views that simulate X-ray scans, and (2) 3D partial vertebrae representations that mimic the limited visibility and occlusions encountered during ultrasound spine imaging. Our method integrates morphological information from both imaging modalities and demonstrates significant improvements in vertebral reconstruction (p < 0.001) compared to state of art in 3D ultrasound vertebral completion. We perform phantom studies as an initial step to future clinical translation, and achieve a more accurate, complete volumetric lumbar spine visualization overlayed on the ultrasound scan without the need for registration with preoperative modalities such as computed tomography. This demonstrates that integrating a single X-ray projection mitigates ultrasound's key limitation while preserving its strengths as the primary imaging modality. Code and data can be found at https://github.com/miruna20/US-X-Complete","cs.CV, cs.LG",2025-11-19 16:45:04+00:00,ultrasound offer radiationfree costeffective solution realtime visualization spinal landmark paraspinal soft tissue neurovascular structure making valuable intraoperative guidance spinal procedure however ultrasound suffers inherent limitation visualizing complete vertebral anatomy particular vertebral body due acoustic shadowing effect caused bone work present novel multimodal deep learning method completing occluded anatomical structure 3d ultrasound leveraging complementary information single xray image enable training generate paired training data consisting 1 2d lateral vertebral view simulate xray scan 2 3d partial vertebra representation mimic limited visibility occlusion encountered ultrasound spine imaging method integrates morphological information imaging modality demonstrates significant improvement vertebral reconstruction p 0001 compared state art 3d ultrasound vertebral completion perform phantom study initial step future clinical translation achieve accurate complete volumetric lumbar spine visualization overlayed ultrasound scan without need registration preoperative modality computed tomography demonstrates integrating single xray projection mitigates ultrasound key limitation preserving strength primary imaging modality code data found httpsgithubcommiruna20usxcomplete,0,"ultrasound, elastography"
Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition,"Xufei Wang, Junqiao Zhao, Siyue Tao, Qiwen Gu, Wonbong Kim, Tiantian Feng","LiDAR place recognition plays a crucial role in SLAM, robot navigation, and autonomous driving. However, existing LiDAR place recognition methods often struggle to adapt to new environments without forgetting previously learned knowledge, a challenge widely known as catastrophic forgetting. To address this issue, we propose KDF+, a novel continual learning framework for LiDAR place recognition that extends the KDF paradigm with a loss-aware sampling strategy and a rehearsal enhancement mechanism. The proposed sampling strategy estimates the learning difficulty of each sample via its loss value and selects samples for replay according to their estimated difficulty. Harder samples, which tend to encode more discriminative information, are sampled with higher probability while maintaining distributional coverage across the dataset. In addition, the rehearsal enhancement mechanism encourages memory samples to be further refined during new-task training by slightly reducing their loss relative to previous tasks, thereby reinforcing long-term knowledge retention. Extensive experiments across multiple benchmarks demonstrate that KDF+ consistently outperforms existing continual learning methods and can be seamlessly integrated into state-of-the-art continual learning for LiDAR place recognition frameworks to yield significant and stable performance gains. The code will be available at https://github.com/repo/KDF-plus.",cs.CV,2025-11-19 16:41:30+00:00,lidar place recognition play crucial role slam robot navigation autonomous driving however existing lidar place recognition method often struggle adapt new environment without forgetting previously learned knowledge challenge widely known catastrophic forgetting address issue propose kdf novel continual learning framework lidar place recognition extends kdf paradigm lossaware sampling strategy rehearsal enhancement mechanism proposed sampling strategy estimate learning difficulty sample via loss value selects sample replay according estimated difficulty harder sample tend encode discriminative information sampled higher probability maintaining distributional coverage across dataset addition rehearsal enhancement mechanism encourages memory sample refined newtask training slightly reducing loss relative previous task thereby reinforcing longterm knowledge retention extensive experiment across multiple benchmark demonstrate kdf consistently outperforms existing continual learning method seamlessly integrated stateoftheart continual learning lidar place recognition framework yield significant stable performance gain code available httpsgithubcomrepokdfplus,8,"cnntransformer, ssmixnet"
What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity,"Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach","AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.",cs.AI,2025-11-19 16:32:18+00:00,ai research agent offer promise accelerate scientific progress automating design implementation training machine learning model however field still infancy key factor driving success failure agent trajectory fully understood examine role ideation diversity play agent performance first analyse agent trajectory mlebench wellknown benchmark evaluate ai research agent across different model agent scaffold analysis reveals different model agent scaffold yield varying degree ideation diversity higherperforming agent tend increased ideation diversity run controlled experiment modify degree ideation diversity demonstrating higher ideation diversity result stronger performance finally strengthen result examining additional evaluation metric beyond standard medalbased scoring mlebench showing finding still hold across agent performance metric,1,"rescuelens, volunteer"
A critical review of pre-post surveys designed to measure student epistemology in undergraduate science courses,"Kyriaki Chatzikyriakidou, Kristi L. Hall, Edward F. Redish, Todd J. Cooke","The epistemology of science students, i.e., their beliefs about the nature of the knowledge they are learning, about what they have to do to learn it, and about how they will use that knowledge, often plays a powerful role in what they learn in their science courses. This perspective paper provides a broad overview of the theoretical frameworks, designs, and applications of online pre-post surveys that are available to assess the potential shifts in epistemic perspectives in undergraduate science courses. We pay particular attention to a recent survey for biology courses called the Maryland Biological Expectation Survey (MBEX). The MBEX was developed to probe four epistemic themes that are closely aligned with the Vision and Change initiative for reforming undergraduate biology education. This review is intended to inform STEM teachers about the availability of online epistemological surveys for evaluating the epistemic effects of their courses. These surveys can also help STEM education researchers readily evaluate how different pedagogies, classroom contexts, and other features of learning environments affect the epistemic perspectives of science students.",physics.ed-ph,2025-11-19 16:07:36+00:00,epistemology science student ie belief nature knowledge learning learn use knowledge often play powerful role learn science course perspective paper provides broad overview theoretical framework design application online prepost survey available assess potential shift epistemic perspective undergraduate science course pay particular attention recent survey biology course called maryland biological expectation survey mbex mbex developed probe four epistemic theme closely aligned vision change initiative reforming undergraduate biology education review intended inform stem teacher availability online epistemological survey evaluating epistemic effect course survey also help stem education researcher readily evaluate different pedagogy classroom context feature learning environment affect epistemic perspective science student,1,"rescuelens, volunteer"
HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning,"Qihao Yang, Xuelin Wang, Jiale Chen, Xuelian Dong, Yuxin Hao, Tianyong Hao","Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.","cs.CL, cs.AI",2025-11-19 16:06:06+00:00,language acquisition vital revealing nature human language intelligence recently emerged promising perspective improving interpretability large language model llm however ethically practically infeasible conduct experiment require controlling human learner language input pose challenge verifiability scalability language acquisition modeling particularly chinese second language acquisition sla llm provide controllable reproducible alternative systematic benchmark support phasewise modeling assessment still lacking paper present hskbenchmark first benchmark staged modeling writing assessment llm chinese sla cover hsk level 3 6 includes authentic textbook 676 million token 16k synthetic instruction sample 30 test topic linguistically grounded evaluation system simulate human learning trajectory introduce curriculumtuning framework train model beginner advanced level evaluation system created examine levelbased grammar coverage writing error lexical syntactic complexity holistic scoring also build hskagent finetuned 10k learner composition extensive experimental result demonstrate hskbenchmark model chinese sla effectively also serf reliable benchmark dynamic writing assessment llm finetuned llm writing performance par advanced human learner exhibit humanlike acquisition characteristic hskbenchmark hskagent checkpoint serve foundational tool resource potential pave way future research language acquisition modeling llm interpretability code data publicly available httpsgithubcomcharlesyang030hskb,1,"rescuelens, volunteer"
Variance-reduced extreme value index estimators using control variates in a semi-supervised setting,"Louison Bocquet-Nouaille, Jérôme Morio, Benjamin Bobbia","The estimation of the Extreme Value Index (EVI) is fundamental in extreme value analysis but suffers from high variance due to reliance on only a few extreme observations. We propose a control variates based transfer learning approach in a semi-supervised framework, where a small set of coupled target and source observations is combined with abundant unpaired source data. By expressing the Hill estimator of the target EVI as a ratio of means, we apply approximate control variates to both numerator and denominator, with jointly optimized coefficients that guarantee variance reduction without introducing bias. We show theoretically and through simulations that the asymptotic relative variance reduction of the transferred Hill estimator is proportional to the tail dependence between the target and source variables and independent of their EVI values. Thus, substantial variance reduction can be achieved even without similarity in tail heaviness of the target and source distributions. The proposed approach can be extended to other EVI estimators expressed with ratio of means, as demonstrated on the moment estimator. The practical value of the proposed method is illustrated on multi-fidelity water surge and ice accretion datasets.","stat.ME, math.ST",2025-11-19 15:54:42+00:00,estimation extreme value index evi fundamental extreme value analysis suffers high variance due reliance extreme observation propose control variate based transfer learning approach semisupervised framework small set coupled target source observation combined abundant unpaired source data expressing hill estimator target evi ratio mean apply approximate control variate numerator denominator jointly optimized coefficient guarantee variance reduction without introducing bias show theoretically simulation asymptotic relative variance reduction transferred hill estimator proportional tail dependence target source variable independent evi value thus substantial variance reduction achieved even without similarity tail heaviness target source distribution proposed approach extended evi estimator expressed ratio mean demonstrated moment estimator practical value proposed method illustrated multifidelity water surge ice accretion datasets,3,"equipment, evi"
Meta-Black-Box Optimization with Bi-Space Landscape Analysis and Dual-Control Mechanism for SAEA,"Yukun Du, Haiyue Yu, Xiaotong Xie, Yan Zheng, Lixin Zhan, Yudong Du, Chongshuang Hu, Boxuan Wang, Jiang Jiang","Surrogate-Assisted Evolutionary Algorithms (SAEAs) are widely used for expensive Black-Box Optimization. However, their reliance on rigid, manually designed components such as infill criteria and evolutionary strategies during the search process limits their flexibility across tasks. To address these limitations, we propose Dual-Control Bi-Space Surrogate-Assisted Evolutionary Algorithm (DB-SAEA), a Meta-Black-Box Optimization (MetaBBO) framework tailored for multi-objective problems. DB-SAEA learns a meta-policy that jointly regulates candidate generation and infill criterion selection, enabling dual control. The bi-space Exploratory Landscape Analysis (ELA) module in DB-SAEA adopts an attention-based architecture to capture optimization states from both true and surrogate evaluation spaces, while ensuring scalability across problem dimensions, population sizes, and objectives. Additionally, we integrate TabPFN as the surrogate model for accurate and efficient prediction with uncertainty estimation. The framework is trained via reinforcement learning, leveraging parallel sampling and centralized training to enhance efficiency and transferability across tasks. Experimental results demonstrate that DB-SAEA not only outperforms state-of-the-art baselines across diverse benchmarks, but also exhibits strong zero-shot transfer to unseen tasks with higher-dimensional settings. This work introduces the first MetaBBO framework with dual-level control over SAEAs and a bi-space ELA that captures surrogate model information.",cs.NE,2025-11-19 15:43:19+00:00,surrogateassisted evolutionary algorithm saeas widely used expensive blackbox optimization however reliance rigid manually designed component infill criterion evolutionary strategy search process limit flexibility across task address limitation propose dualcontrol bispace surrogateassisted evolutionary algorithm dbsaea metablackbox optimization metabbo framework tailored multiobjective problem dbsaea learns metapolicy jointly regulates candidate generation infill criterion selection enabling dual control bispace exploratory landscape analysis ela module dbsaea adopts attentionbased architecture capture optimization state true surrogate evaluation space ensuring scalability across problem dimension population size objective additionally integrate tabpfn surrogate model accurate efficient prediction uncertainty estimation framework trained via reinforcement learning leveraging parallel sampling centralized training enhance efficiency transferability across task experimental result demonstrate dbsaea outperforms stateoftheart baseline across diverse benchmark also exhibit strong zeroshot transfer unseen task higherdimensional setting work introduces first metabbo framework duallevel control saeas bispace ela capture surrogate model information,9,"visionlanguageaction, geolocalization"
A Physics Informed Machine Learning Framework for Optimal Sensor Placement and Parameter Estimation,"Georgios Venianakis, Constantinos Theodoropoulos, Michail Kavousanakis","Parameter estimation remains a challenging task across many areas of engineering. Because data acquisition can often be costly, limited, or prone to inaccuracies (noise, uncertainty) it is crucial to identify sensor configurations that provide the maximum amount of information about the unknown parameters, in particular for the case of distributed-parameter systems, where spatial variations are important. Physics-Informed Neural Networks (PINNs) have recently emerged as a powerful machine-learning (ML) tool for parameter estimation, particularly in cases with sparse or noisy measurements, overcoming some of the limitations of traditional optimization-based and Bayesian approaches. Despite the widespread use of PINNs for solving inverse problems, relatively little attention has been given to how their performance depends on sensor placement. This study addresses this gap by introducing a comprehensive PINN-based framework that simultaneously tackles optimal sensor placement and parameter estimation. Our approach involves training a PINN model in which the parameters of interest are included as additional inputs. This enables the efficient computation of sensitivity functions through automatic differentiation, which are then used to determine optimal sensor locations exploiting the D-optimality criterion. The framework is validated on two illustrative distributed-parameter reaction-diffusion-advection problems of increasing complexity. The results demonstrate that our PINNs-based methodology consistently achieves higher accuracy compared to parameter values estimated from intuitively or randomly selected sensor positions.","stat.ML, cs.LG",2025-11-19 15:37:17+00:00,parameter estimation remains challenging task across many area engineering data acquisition often costly limited prone inaccuracy noise uncertainty crucial identify sensor configuration provide maximum amount information unknown parameter particular case distributedparameter system spatial variation important physicsinformed neural network pinns recently emerged powerful machinelearning ml tool parameter estimation particularly case sparse noisy measurement overcoming limitation traditional optimizationbased bayesian approach despite widespread use pinns solving inverse problem relatively little attention given performance depends sensor placement study address gap introducing comprehensive pinnbased framework simultaneously tackle optimal sensor placement parameter estimation approach involves training pinn model parameter interest included additional input enables efficient computation sensitivity function automatic differentiation used determine optimal sensor location exploiting doptimality criterion framework validated two illustrative distributedparameter reactiondiffusionadvection problem increasing complexity result demonstrate pinnsbased methodology consistently achieves higher accuracy compared parameter value estimated intuitively randomly selected sensor position,2,"dynamicslearning, sgd"
The VVVX quest for satellites around the Circinus galaxy,"L. D. Baravalle, A. L. O'Mill, M. V. Alonso, C. Obasi, D. Minniti, M. Gómez, C. Villalon, J. Nilo-Castellón, C. Valotto, M. Soto, I. V. Daza Perilla, M. A. Sgró, J. G. Fernández-Trincado","The Circinus galaxy is the nearest type-2 Seyfert galaxy, which is at a distance of 4.2 Mpc. Its environment is challenging to explore because it is located at low Galactic latitudes, behind the Galactic disc. The long-term goal is to characterise the Circinus galaxy halo and determine the presence of dwarf satellites using near-infrared data. We selected 1,542 galaxies from the VVV NIRGC within a 2-degree radius around Circinus, representing 2/3 of the virial radius. Structural parameters such as half-light radii and colours were used, and correlations were examined. A neural network was trained with 486 galaxies with known spectroscopic redshifts to estimate photometric redshifts for all galaxies. Potential satellites were defined based on half-light radii compatible with the typical sizes of dwarf satellites, and combined with photometric redshifts. The galaxy properties are reliably characterised down to $K_{s}$ $\sim$ 15.5 mag, which represents about 90% completeness of detections. At the distance of Circinus, this limiting magnitude corresponds to $K_{s}$ absolute magnitude of $-12.6$ mag, which allows us to find dwarf galaxies. There are 20 galaxies with half-light radii larger than 2.45 arcsec, only 8 have photometric redshifts below 0.04. None of these galaxies is close to Circinus, which has a redshift of 0.0015. The ANNz model exhibited a high degree of accuracy in the range $0.001 < z_{phot} < 0.023$. The presence of dwarf satellites could not be confirmed with the available data in the studied region. The apparent lack of satellites may be genuine, possibly related to AGN feedback effects. This work demonstrates the effectiveness of combining near-infrared data and machine learning techniques to estimate photometric redshifts at low Galactic latitudes, providing useful information for future spectroscopic follow-up campaigns.",astro-ph.GA,2025-11-19 15:37:09+00:00,circinus galaxy nearest type2 seyfert galaxy distance 42 mpc environment challenging explore located low galactic latitude behind galactic disc longterm goal characterise circinus galaxy halo determine presence dwarf satellite using nearinfrared data selected 1542 galaxy vvv nirgc within 2degree radius around circinus representing 23 virial radius structural parameter halflight radius colour used correlation examined neural network trained 486 galaxy known spectroscopic redshift estimate photometric redshift galaxy potential satellite defined based halflight radius compatible typical size dwarf satellite combined photometric redshift galaxy property reliably characterised k_s sim 155 mag represents 90 completeness detection distance circinus limiting magnitude corresponds k_s absolute magnitude 126 mag allows u find dwarf galaxy 20 galaxy halflight radius larger 245 arcsec 8 photometric redshift 004 none galaxy close circinus redshift 00015 annz model exhibited high degree accuracy range 0001 z_phot 0023 presence dwarf satellite could confirmed available data studied region apparent lack satellite may genuine possibly related agn feedback effect work demonstrates effectiveness combining nearinfrared data machine learning technique estimate photometric redshift low galactic latitude providing useful information future spectroscopic followup campaign,5,"tokenisation, tokenisers"
A Hybrid CNN-ViT-GNN Framework with GAN-Based Augmentation for Intelligent Weed Detection in Precision Agriculture,"Pandiyaraju V, Abishek Karthik, Sreya Mynampati, Poovarasan L, D. Saraswathi","The task of weed detection is an essential element of precision agriculture since accurate species identification allows a farmer to selectively apply herbicides and fits into sustainable agriculture crop management. This paper proposes a hybrid deep learning framework recipe for weed detection that utilizes Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), and Graph Neural Networks (GNNs) to build robustness to multiple field conditions. A Generative Adversarial Network (GAN)-based augmentation method was imposed to balance class distributions and better generalize the model. Further, a self-supervised contrastive pre-training method helps to learn more features from limited annotated data. Experimental results yield superior results with 99.33% accuracy, precision, recall, and F1-score on multi-benchmark datasets. The proposed model architecture enables local, global, and relational feature representations and offers high interpretability and adaptability. Practically, the framework allows real-time, efficient deployment to edge devices for automated weed detecting, reducing over-reliance on herbicides and providing scalable, sustainable precision-farming options.",cs.CV,2025-11-19 15:32:08+00:00,task weed detection essential element precision agriculture since accurate specie identification allows farmer selectively apply herbicide fit sustainable agriculture crop management paper proposes hybrid deep learning framework recipe weed detection utilizes convolutional neural network cnns vision transformer vits graph neural network gnns build robustness multiple field condition generative adversarial network ganbased augmentation method imposed balance class distribution better generalize model selfsupervised contrastive pretraining method help learn feature limited annotated data experimental result yield superior result 9933 accuracy precision recall f1score multibenchmark datasets proposed model architecture enables local global relational feature representation offer high interpretability adaptability practically framework allows realtime efficient deployment edge device automated weed detecting reducing overreliance herbicide providing scalable sustainable precisionfarming option,8,"cnntransformer, ssmixnet"
Exploring the use of AI authors and reviewers at Agents4Science,"Federico Bianchi, Owen Queen, Nitya Thakkar, Eric Sun, James Zou","There is growing interest in using AI agents for scientific research, yet fundamental questions remain about their capabilities as scientists and reviewers. To explore these questions, we organized Agents4Science, the first conference in which AI agents serve as both primary authors and reviewers, with humans as co-authors and co-reviewers. Here, we discuss the key learnings from the conference and their implications for human-AI collaboration in science.",cs.AI,2025-11-19 15:32:07+00:00,growing interest using ai agent scientific research yet fundamental question remain capability scientist reviewer explore question organized agents4science first conference ai agent serve primary author reviewer human coauthor coreviewers discus key learning conference implication humanai collaboration science,1,"rescuelens, volunteer"
Convergence and Sketching-Based Efficient Computation of Neural Tangent Kernel Weights in Physics-Based Loss,"Max Hirsch, Federico Pichi","In multi-objective optimization, multiple loss terms are weighted and added together to form a single objective. These weights are chosen to properly balance the competing losses according to some meta-goal. For example, in physics-informed neural networks (PINNs), these weights are often adaptively chosen to improve the network's generalization error. A popular choice of adaptive weights is based on the neural tangent kernel (NTK) of the PINN, which describes the evolution of the network in predictor space during training. The convergence of such an adaptive weighting algorithm is not clear a priori. Moreover, these NTK-based weights would be updated frequently during training, further increasing the computational burden of the learning process. In this paper, we prove that under appropriate conditions, gradient descent enhanced with adaptive NTK-based weights is convergent in a suitable sense. We then address the problem of computational efficiency by developing a randomized algorithm inspired by a predictor-corrector approach and matrix sketching, which produces unbiased estimates of the NTK up to an arbitrarily small discretization error. Finally, we provide numerical experiments to support our theoretical findings and to show the efficacy of our randomized algorithm. Code Availability: https://github.com/maxhirsch/Efficient-NTK","math.NA, cs.LG",2025-11-19 15:29:42+00:00,multiobjective optimization multiple loss term weighted added together form single objective weight chosen properly balance competing loss according metagoal example physicsinformed neural network pinns weight often adaptively chosen improve network generalization error popular choice adaptive weight based neural tangent kernel ntk pinn describes evolution network predictor space training convergence adaptive weighting algorithm clear priori moreover ntkbased weight would updated frequently training increasing computational burden learning process paper prove appropriate condition gradient descent enhanced adaptive ntkbased weight convergent suitable sense address problem computational efficiency developing randomized algorithm inspired predictorcorrector approach matrix sketching produce unbiased estimate ntk arbitrarily small discretization error finally provide numerical experiment support theoretical finding show efficacy randomized algorithm code availability httpsgithubcommaxhirschefficientntk,8,"cnntransformer, ssmixnet"
Decentralized Gaussian Process Classification and an Application in Subsea Robotics,"Yifei Gao, Hans J. He, Daniel J. Stilwell, James McMahon","Teams of cooperating autonomous underwater vehicles (AUVs) rely on acoustic communication for coordination, yet this communication medium is constrained by limited range, multi-path effects, and low bandwidth. One way to address the uncertainty associated with acoustic communication is to learn the communication environment in real-time. We address the challenge of a team of robots building a map of the probability of communication success from one location to another in real-time. This is a decentralized classification problem -- communication events are either successful or unsuccessful -- where AUVs share a subset of their communication measurements to build the map. The main contribution of this work is a rigorously derived data sharing policy that selects measurements to be shared among AUVs. We experimentally validate our proposed sharing policy using real acoustic communication data collected from teams of Virginia Tech 690 AUVs, demonstrating its effectiveness in underwater environments.","cs.RO, cs.LG",2025-11-19 15:26:47+00:00,team cooperating autonomous underwater vehicle auvs rely acoustic communication coordination yet communication medium constrained limited range multipath effect low bandwidth one way address uncertainty associated acoustic communication learn communication environment realtime address challenge team robot building map probability communication success one location another realtime decentralized classification problem communication event either successful unsuccessful auvs share subset communication measurement build map main contribution work rigorously derived data sharing policy selects measurement shared among auvs experimentally validate proposed sharing policy using real acoustic communication data collected team virginia tech 690 auvs demonstrating effectiveness underwater environment,1,"rescuelens, volunteer"
PCARNN-DCBF: Minimal-Intervention Geofence Enforcement for Ground Vehicles,"Yinan Yu, Samuel Scheidegger","Runtime geofencing for ground vehicles is rapidly emerging as a critical technology for enforcing Operational Design Domains (ODDs). However, existing solutions struggle to reconcile high-fidelity learning with the structural requirements of verifiable control. We address this by introducing PCARNN-DCBF, a novel pipeline integrating a Physics-encoded Control-Affine Residual Neural Network with a preview-based Discrete Control Barrier Function. Unlike generic learned models, PCARNN explicitly preserves the control-affine structure of vehicle dynamics, ensuring the linearity required for reliable optimization. This enables the DCBF to enforce polygonal keep-in constraints via a real-time Quadratic Program (QP) that handles high relative degree and mitigates actuator saturation. Experiments in CARLA across electric and combustion platforms demonstrate that this structure-preserving approach significantly outperforms analytical and unstructured neural baselines.","cs.LG, cs.RO",2025-11-19 15:19:32+00:00,runtime geofencing ground vehicle rapidly emerging critical technology enforcing operational design domain odds however existing solution struggle reconcile highfidelity learning structural requirement verifiable control address introducing pcarnndcbf novel pipeline integrating physicsencoded controlaffine residual neural network previewbased discrete control barrier function unlike generic learned model pcarnn explicitly preserve controlaffine structure vehicle dynamic ensuring linearity required reliable optimization enables dcbf enforce polygonal keepin constraint via realtime quadratic program qp handle high relative degree mitigates actuator saturation experiment carla across electric combustion platform demonstrate structurepreserving approach significantly outperforms analytical unstructured neural baseline,2,"dynamicslearning, sgd"
Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies,"Gabriel Lauzier, Alexandre Girard, François Ferland","Diffusion Policy has shown great performance in robotic manipulation tasks under stochastic perturbations, due to its ability to model multimodal action distributions. Nonetheless, its reliance on a computationally expensive reverse-time diffusion (denoising) process, for action inference, makes it challenging to use for real-time applications where quick decision-making is mandatory. This work studies the possibility of conducting the denoising process only partially before executing an action, allowing the plant to evolve according to its dynamics in parallel to the reverse-time diffusion dynamics ongoing on the computer. In a classical diffusion policy setting, the plant dynamics are usually slow and the two dynamical processes are uncoupled. Here, we investigate theoretical bounds on the stability of closed-loop systems using diffusion policies when the plant dynamics and the denoising dynamics are coupled. The contribution of this work gives a framework for faster imitation learning and a metric that yields if a controller will be stable based on the variance of the demonstrations.","cs.RO, cs.AI",2025-11-19 15:13:08+00:00,diffusion policy shown great performance robotic manipulation task stochastic perturbation due ability model multimodal action distribution nonetheless reliance computationally expensive reversetime diffusion denoising process action inference make challenging use realtime application quick decisionmaking mandatory work study possibility conducting denoising process partially executing action allowing plant evolve according dynamic parallel reversetime diffusion dynamic ongoing computer classical diffusion policy setting plant dynamic usually slow two dynamical process uncoupled investigate theoretical bound stability closedloop system using diffusion policy plant dynamic denoising dynamic coupled contribution work give framework faster imitation learning metric yield controller stable based variance demonstration,2,"dynamicslearning, sgd"
Revealing the Atomistic Mechanism of Rare Events in Molecular Dynamics,"Jakob J. Kresse, Alexander Sikorski, Marcus Weber","Interpretable reaction coordinates are essential for understanding rare conformational transitions in molecular dynamics. The Atomistic Mechanism Of Rare Events in Molecular Dynamics (AMORE-MD) framework enhances interpretability of deep-learned reaction coordinates by connecting them to atomistic mechanisms, without requiring any a priori knowledge of collective variables, pathways, or endpoints. Here, AMORE-MD employs the ISOKANN algorithm to learn a neural membership function $χ$ representing the dominant slow process, from which transition pathways are reconstructed as minimum-energy paths aligned with the gradient of $χ$, and atomic contributions are quantified through gradient-based sensitivity analysis. Iterative enhanced sampling further enriches transition regions and improves coverage of rare events enabling recovery of known mechanisms and chemically interpretable structural rearrangements at atomic resolution for the Müller-Brown potential, alanine dipeptide, and the elastin-derived hexapeptide VGVAPG.",physics.chem-ph,2025-11-19 15:07:43+00:00,interpretable reaction coordinate essential understanding rare conformational transition molecular dynamic atomistic mechanism rare event molecular dynamic amoremd framework enhances interpretability deeplearned reaction coordinate connecting atomistic mechanism without requiring priori knowledge collective variable pathway endpoint amoremd employ isokann algorithm learn neural membership function χ representing dominant slow process transition pathway reconstructed minimumenergy path aligned gradient χ atomic contribution quantified gradientbased sensitivity analysis iterative enhanced sampling enriches transition region improves coverage rare event enabling recovery known mechanism chemically interpretable structural rearrangement atomic resolution müllerbrown potential alanine dipeptide elastinderived hexapeptide vgvapg,8,"cnntransformer, ssmixnet"
Multimodal Optical Imaging Platform for Quantitative Burn Assessment,"Nathaniel Hanson, Mateusz Wolak, Jonathan Richardson, Patrick Walker, David M. Burmeister, Chakameh Jafari","Accurate assessment of burn severity at injury onset remains a major clinical challenge due to the lack of objective methods for detecting subsurface tissue damage. This limitation is critical in battlefield and mass-casualty settings, where rapid and reliable evaluation of burn depth is essential for triage and surgical decision-making. We present a multimodal optical imaging framework that establishes the foundation for a compact, low-size, weight, and power (low-SWaP) field-deployable device for quantitative burn assessment. The system integrates broadband hyperspectral imaging (VSWIR, 400 -- 2100 nm) with laser speckle contrast imaging to jointly evaluate biochemical composition and microvascular perfusion. Using short-wave infrared (SWIR, >1000 nm) wavelengths, we developed and validated novel deep-tissue parameters linked to water, lipid, and collagen absorption features that enhance burn-tissue separability and burn severity classification. We implemented and validated unsupervised learning methods for spectral feature extraction, band down-selection, and clustering against histology, establishing a foundation for a rugged, data-driven device for early quantitative burn evaluation in austere environments.",eess.IV,2025-11-19 15:03:41+00:00,accurate assessment burn severity injury onset remains major clinical challenge due lack objective method detecting subsurface tissue damage limitation critical battlefield masscasualty setting rapid reliable evaluation burn depth essential triage surgical decisionmaking present multimodal optical imaging framework establishes foundation compact lowsize weight power lowswap fielddeployable device quantitative burn assessment system integrates broadband hyperspectral imaging vswir 400 2100 nm laser speckle contrast imaging jointly evaluate biochemical composition microvascular perfusion using shortwave infrared swir 1000 nm wavelength developed validated novel deeptissue parameter linked water lipid collagen absorption feature enhance burntissue separability burn severity classification implemented validated unsupervised learning method spectral feature extraction band downselection clustering histology establishing foundation rugged datadriven device early quantitative burn evaluation austere environment,0,"ultrasound, elastography"
Sample-Adaptivity Tradeoff in On-Demand Sampling,"Nika Haghtalab, Omar Montasser, Mingda Qiao","We study the tradeoff between sample complexity and round complexity in on-demand sampling, where the learning algorithm adaptively samples from $k$ distributions over a limited number of rounds. In the realizable setting of Multi-Distribution Learning (MDL), we show that the optimal sample complexity of an $r$-round algorithm scales approximately as $dk^{Θ(1/r)} / ε$. For the general agnostic case, we present an algorithm that achieves near-optimal sample complexity of $\widetilde O((d + k) / ε^2)$ within $\widetilde O(\sqrt{k})$ rounds. Of independent interest, we introduce a new framework, Optimization via On-Demand Sampling (OODS), which abstracts the sample-adaptivity tradeoff and captures most existing MDL algorithms. We establish nearly tight bounds on the round complexity in the OODS setting. The upper bounds directly yield the $\widetilde O(\sqrt{k})$-round algorithm for agnostic MDL, while the lower bounds imply that achieving sub-polynomial round complexity would require fundamentally new techniques that bypass the inherent hardness of OODS.","cs.LG, cs.DS, stat.ML",2025-11-19 14:59:47+00:00,study tradeoff sample complexity round complexity ondemand sampling learning algorithm adaptively sample k distribution limited number round realizable setting multidistribution learning mdl show optimal sample complexity rround algorithm scale approximately dkθ1r ε general agnostic case present algorithm achieves nearoptimal sample complexity widetilde od k ε2 within widetilde osqrtk round independent interest introduce new framework optimization via ondemand sampling oods abstract sampleadaptivity tradeoff capture existing mdl algorithm establish nearly tight bound round complexity oods setting upper bound directly yield widetilde osqrtkround algorithm agnostic mdl lower bound imply achieving subpolynomial round complexity would require fundamentally new technique bypass inherent hardness oods,2,"dynamicslearning, sgd"
Game Master LLM: Task-Based Role-Playing for Natural Slang Learning,"Amir Tahmasbi, Milad Esrafilian, Judson Wright, Sooyeon Jeong, Aniket Bera","Natural and idiomatic expressions are essential for fluent, everyday communication, yet many second-language learners struggle to acquire and spontaneously use casual slang despite strong formal proficiency. To address this gap, we designed and evaluated an LLM-powered, task-based role-playing game in which a GPT-4o-based Game Master guides learners through an immersive, three-phase spoken narrative. After selecting five unfamiliar slang phrases to practice, participants engage in open-ended dialogue with non-player characters; the Game Master naturally incorporates the target phrases in rich semantic contexts (implicit input enhancement) while a dedicated Practice Box provides real-time explicit tracking and encouragement. Post-session, learners receive multi-level formative feedback analyzing the entire interaction.
  We evaluated the system in a between-subjects study with 14 international graduate students, randomly assigned to either the RPG condition or a control condition consisting of a traditional AI-led virtual classroom. Results from an immediate post-test show that the RPG group achieved greater gains in both comprehension of the target phrases and their accurate, contextual use in sentences. Quantitative analysis of in-activity word-usage frequency, combined with qualitative survey responses, further indicates that the game-based approach provided more practice opportunities and higher perceived engagement, resulting in a more natural learning experience. These findings highlight the potential of narrative-driven LLM interactions in vocabulary acquisition.",cs.HC,2025-11-19 14:58:34+00:00,natural idiomatic expression essential fluent everyday communication yet many secondlanguage learner struggle acquire spontaneously use casual slang despite strong formal proficiency address gap designed evaluated llmpowered taskbased roleplaying game gpt4obased game master guide learner immersive threephase spoken narrative selecting five unfamiliar slang phrase practice participant engage openended dialogue nonplayer character game master naturally incorporates target phrase rich semantic context implicit input enhancement dedicated practice box provides realtime explicit tracking encouragement postsession learner receive multilevel formative feedback analyzing entire interaction evaluated system betweensubjects study 14 international graduate student randomly assigned either rpg condition control condition consisting traditional ailed virtual classroom result immediate posttest show rpg group achieved greater gain comprehension target phrase accurate contextual use sentence quantitative analysis inactivity wordusage frequency combined qualitative survey response indicates gamebased approach provided practice opportunity higher perceived engagement resulting natural learning experience finding highlight potential narrativedriven llm interaction vocabulary acquisition,1,"rescuelens, volunteer"
A Tensor Compiler for Processing-In-Memory Architectures,"Peiming Yang, Sankeerth Durvasula, Ivan Fernandez, Mohammad Sadrosadati, Onur Mutlu, Gennady Pekhimenko, Christina Giannoula","Processing-In-Memory (PIM) devices integrated with high-performance Host processors (e.g., GPUs) can accelerate memory-intensive kernels in Machine Learning (ML) models, including Large Language Models (LLMs), by leveraging high memory bandwidth at PIM cores. However, Host processors and PIM cores require different data layouts: Hosts need consecutive elements distributed across DRAM banks, while PIM cores need them within local banks. This necessitates data rearrangements in ML kernel execution that pose significant performance and programmability challenges, further exacerbated by the need to support diverse PIM backends. Current compilation approaches lack systematic optimization for diverse ML kernels across multiple PIM backends and may largely ignore data rearrangements during compute code optimization. We demonstrate that data rearrangements and compute code optimization are interdependent, and need to be jointly optimized during the tuning process. To address this, we design DCC, the first data-centric ML compiler for PIM systems that jointly co-optimizes data rearrangements and compute code in a unified tuning process. DCC integrates a multi-layer PIM abstraction that enables various data distribution and processing strategies on different PIM backends. DCC enables effective co-optimization by mapping data partitioning strategies to compute loop partitions, applying PIM-specific code optimizations and leveraging a fast and accurate performance prediction model to select optimal configurations. Our evaluations in various individual ML kernels demonstrate that DCC achieves up to 7.68x speedup (2.7x average) on HBM-PIM and up to 13.17x speedup (5.75x average) on AttAcc PIM backend over GPU-only execution. In end-to-end LLM inference, DCC on AttAcc accelerates GPT-3 and LLaMA-2 by up to 7.71x (4.88x average) over GPU.","cs.AR, cs.DC, cs.LG, cs.PF",2025-11-19 14:58:16+00:00,processinginmemory pim device integrated highperformance host processor eg gpus accelerate memoryintensive kernel machine learning ml model including large language model llm leveraging high memory bandwidth pim core however host processor pim core require different data layout host need consecutive element distributed across dram bank pim core need within local bank necessitates data rearrangement ml kernel execution pose significant performance programmability challenge exacerbated need support diverse pim backends current compilation approach lack systematic optimization diverse ml kernel across multiple pim backends may largely ignore data rearrangement compute code optimization demonstrate data rearrangement compute code optimization interdependent need jointly optimized tuning process address design dcc first datacentric ml compiler pim system jointly cooptimizes data rearrangement compute code unified tuning process dcc integrates multilayer pim abstraction enables various data distribution processing strategy different pim backends dcc enables effective cooptimization mapping data partitioning strategy compute loop partition applying pimspecific code optimization leveraging fast accurate performance prediction model select optimal configuration evaluation various individual ml kernel demonstrate dcc achieves 768x speedup 27x average hbmpim 1317x speedup 575x average attacc pim backend gpuonly execution endtoend llm inference dcc attacc accelerates gpt3 llama2 771x 488x average gpu,4,"forgetting, memoryintensive"
Learning to Expand Images for Efficient Visual Autoregressive Modeling,"Ruiqing Yang, Kaixin Zhang, Zheng Zhang, Shan You, Tao Huang","Autoregressive models have recently shown great promise in visual generation by leveraging discrete token sequences akin to language modeling. However, existing approaches often suffer from inefficiency, either due to token-by-token decoding or the complexity of multi-scale representations. In this work, we introduce Expanding Autoregressive Representation (EAR), a novel generation paradigm that emulates the human visual system's center-outward perception pattern. EAR unfolds image tokens in a spiral order from the center and progressively expands outward, preserving spatial continuity and enabling efficient parallel decoding. To further enhance flexibility and speed, we propose a length-adaptive decoding strategy that dynamically adjusts the number of tokens predicted at each step. This biologically inspired design not only reduces computational cost but also improves generation quality by aligning the generation order with perceptual relevance. Extensive experiments on ImageNet demonstrate that EAR achieves state-of-the-art trade-offs between fidelity and efficiency on single-scale autoregressive models, setting a new direction for scalable and cognitively aligned autoregressive image generation.",cs.CV,2025-11-19 14:55:07+00:00,autoregressive model recently shown great promise visual generation leveraging discrete token sequence akin language modeling however existing approach often suffer inefficiency either due tokenbytoken decoding complexity multiscale representation work introduce expanding autoregressive representation ear novel generation paradigm emulates human visual system centeroutward perception pattern ear unfolds image token spiral order center progressively expands outward preserving spatial continuity enabling efficient parallel decoding enhance flexibility speed propose lengthadaptive decoding strategy dynamically adjusts number token predicted step biologically inspired design reduces computational cost also improves generation quality aligning generation order perceptual relevance extensive experiment imagenet demonstrate ear achieves stateoftheart tradeoff fidelity efficiency singlescale autoregressive model setting new direction scalable cognitively aligned autoregressive image generation,4,"forgetting, memoryintensive"
A Review of Machine Learning for Cavitation Intensity Recognition in Complex Industrial Systems,"Yu Sha, Ningtao Liu, Haofeng Liu, Junqi Tao, Zhenxing Niu, Guojun Huang, Yao Yao, Jiaqi Liang, Moxian Qian, Horst Stoecker, Domagoj Vnucec, Andreas Widl, Kai Zhou","Cavitation intensity recognition (CIR) is a critical technology for detecting and evaluating cavitation phenomena in hydraulic machinery, with significant implications for operational safety, performance optimization, and maintenance cost reduction in complex industrial systems. Despite substantial research progress, a comprehensive review that systematically traces the development trajectory and provides explicit guidance for future research is still lacking. To bridge this gap, this paper presents a thorough review and analysis of hundreds of publications on intelligent CIR across various types of mechanical equipment from 2002 to 2025, summarizing its technological evolution and offering insights for future development. The early stages are dominated by traditional machine learning approaches that relied on manually engineered features under the guidance of domain expert knowledge. The advent of deep learning has driven the development of end-to-end models capable of automatically extracting features from multi-source signals, thereby significantly improving recognition performance and robustness. Recently, physical informed diagnostic models have been proposed to embed domain knowledge into deep learning models, which can enhance interpretability and cross-condition generalization. In the future, transfer learning, multi-modal fusion, lightweight network architectures, and the deployment of industrial agents are expected to propel CIR technology into a new stage, addressing challenges in multi-source data acquisition, standardized evaluation, and industrial implementation. The paper aims to systematically outline the evolution of CIR technology and highlight the emerging trend of integrating deep learning with physical knowledge. This provides a significant reference for researchers and practitioners in the field of intelligent cavitation diagnosis in complex industrial systems.",eess.SP,2025-11-19 14:53:48+00:00,cavitation intensity recognition cir critical technology detecting evaluating cavitation phenomenon hydraulic machinery significant implication operational safety performance optimization maintenance cost reduction complex industrial system despite substantial research progress comprehensive review systematically trace development trajectory provides explicit guidance future research still lacking bridge gap paper present thorough review analysis hundred publication intelligent cir across various type mechanical equipment 2002 2025 summarizing technological evolution offering insight future development early stage dominated traditional machine learning approach relied manually engineered feature guidance domain expert knowledge advent deep learning driven development endtoend model capable automatically extracting feature multisource signal thereby significantly improving recognition performance robustness recently physical informed diagnostic model proposed embed domain knowledge deep learning model enhance interpretability crosscondition generalization future transfer learning multimodal fusion lightweight network architecture deployment industrial agent expected propel cir technology new stage addressing challenge multisource data acquisition standardized evaluation industrial implementation paper aim systematically outline evolution cir technology highlight emerging trend integrating deep learning physical knowledge provides significant reference researcher practitioner field intelligent cavitation diagnosis complex industrial system,3,"equipment, evi"
Evaluating Low-Light Image Enhancement Across Multiple Intensity Levels,"Maria Pilligua, David Serrano-Lozano, Pai Peng, Ramon Baldrich, Michael S. Brown, Javier Vazquez-Corral","Imaging in low-light environments is challenging due to reduced scene radiance, which leads to elevated sensor noise and reduced color saturation. Most learning-based low-light enhancement methods rely on paired training data captured under a single low-light condition and a well-lit reference. The lack of radiance diversity limits our understanding of how enhancement techniques perform across varying illumination intensities. We introduce the Multi-Illumination Low-Light (MILL) dataset, containing images captured at diverse light intensities under controlled conditions with fixed camera settings and precise illuminance measurements. MILL enables comprehensive evaluation of enhancement algorithms across variable lighting conditions. We benchmark several state-of-the-art methods and reveal significant performance variations across intensity levels. Leveraging the unique multi-illumination structure of our dataset, we propose improvements that enhance robustness across diverse illumination scenarios. Our modifications achieve up to 10 dB PSNR improvement for DSLR and 2 dB for the smartphone on Full HD images.","cs.CV, cs.AI",2025-11-19 14:52:51+00:00,imaging lowlight environment challenging due reduced scene radiance lead elevated sensor noise reduced color saturation learningbased lowlight enhancement method rely paired training data captured single lowlight condition welllit reference lack radiance diversity limit understanding enhancement technique perform across varying illumination intensity introduce multiillumination lowlight mill dataset containing image captured diverse light intensity controlled condition fixed camera setting precise illuminance measurement mill enables comprehensive evaluation enhancement algorithm across variable lighting condition benchmark several stateoftheart method reveal significant performance variation across intensity level leveraging unique multiillumination structure dataset propose improvement enhance robustness across diverse illumination scenario modification achieve 10 db psnr improvement dslr 2 db smartphone full hd image,8,"cnntransformer, ssmixnet"
FDR Control via Neural Networks under Covariate-Dependent Symmetric Nulls,"Taehyoung Kim, Seohwa Hwang, Junyong Park","In modern multiple hypothesis testing, the availability of covariate information alongside the primary test statistics has motivated the development of more powerful and adaptive inference methods. However, most existing approaches rely on p-values that are precomputed under the assumption that their null distributions are independent of the covariates. In this paper, we propose a framework that derives covariate-adaptive p-values from the assumption of a symmetric null distribution of the primary variable given the covariates, without imposing any parametric assumptions. Building on these data-driven p-values, we employ a neural network model to learn a covariate-adaptive rejection threshold via the mirror estimation principle, optimizing the number of discoveries while maintaining valid false discovery rate control. Furthermore, our estimation of the conditional null distribution enables the computation of p-values directly from the raw data. The proposed method provides a principled way to derive covariate-adjusted p-values from raw data and allows seamless integration with previously established p-value based procedures. Simulation studies show that the proposed method outperforms existing approaches in terms of power. We further illustrate its applicability through two real data analyses: age-specific blood pressure data and U.S. air pollution data.",stat.ME,2025-11-19 14:52:41+00:00,modern multiple hypothesis testing availability covariate information alongside primary test statistic motivated development powerful adaptive inference method however existing approach rely pvalues precomputed assumption null distribution independent covariates paper propose framework derives covariateadaptive pvalues assumption symmetric null distribution primary variable given covariates without imposing parametric assumption building datadriven pvalues employ neural network model learn covariateadaptive rejection threshold via mirror estimation principle optimizing number discovery maintaining valid false discovery rate control furthermore estimation conditional null distribution enables computation pvalues directly raw data proposed method provides principled way derive covariateadjusted pvalues raw data allows seamless integration previously established pvalue based procedure simulation study show proposed method outperforms existing approach term power illustrate applicability two real data analysis agespecific blood pressure data u air pollution data,5,"tokenisation, tokenisers"
NTK-Guided Implicit Neural Teaching,"Chen Zhang, Wei Zuo, Bingyang Cheng, Yikun Wang, Wei-Bin Kou, Yik Chung WU, Ngai Wong","Implicit Neural Representations (INRs) parameterize continuous signals via multilayer perceptrons (MLPs), enabling compact, resolution-independent modeling for tasks like image, audio, and 3D reconstruction. However, fitting high-resolution signals demands optimizing over millions of coordinates, incurring prohibitive computational costs. To address it, we propose NTK-Guided Implicit Neural Teaching (NINT), which accelerates training by dynamically selecting coordinates that maximize global functional updates. Leveraging the Neural Tangent Kernel (NTK), NINT scores examples by the norm of their NTK-augmented loss gradients, capturing both fitting errors and heterogeneous leverage (self-influence and cross-coordinate coupling). This dual consideration enables faster convergence compared to existing methods. Through extensive experiments, we demonstrate that NINT significantly reduces training time by nearly half while maintaining or improving representation quality, establishing state-of-the-art acceleration among recent sampling-based strategies.","cs.LG, cs.CV",2025-11-19 14:43:04+00:00,implicit neural representation inr parameterize continuous signal via multilayer perceptrons mlps enabling compact resolutionindependent modeling task like image audio 3d reconstruction however fitting highresolution signal demand optimizing million coordinate incurring prohibitive computational cost address propose ntkguided implicit neural teaching nint accelerates training dynamically selecting coordinate maximize global functional update leveraging neural tangent kernel ntk nint score example norm ntkaugmented loss gradient capturing fitting error heterogeneous leverage selfinfluence crosscoordinate coupling dual consideration enables faster convergence compared existing method extensive experiment demonstrate nint significantly reduces training time nearly half maintaining improving representation quality establishing stateoftheart acceleration among recent samplingbased strategy,7,"supervised, audio"
FunnyNodules: A Customizable Medical Dataset Tailored for Evaluating Explainable AI,"Luisa Gallée, Yiheng Xiong, Meinrad Beer, Michael Götz","Densely annotated medical image datasets that capture not only diagnostic labels but also the underlying reasoning behind these diagnoses are scarce. Such reasoning-related annotations are essential for developing and evaluating explainable AI (xAI) models that reason similarly to radiologists: making correct predictions for the right reasons. To address this gap, we introduce FunnyNodules, a fully parameterized synthetic dataset designed for systematic analysis of attribute-based reasoning in medical AI models. The dataset generates abstract, lung nodule-like shapes with controllable visual attributes such as roundness, margin sharpness, and spiculation. Target class is derived from a predefined attribute combination, allowing full control over the decision rule that links attributes to the diagnostic class. We demonstrate how FunnyNodules can be used in model-agnostic evaluations to assess whether models learn correct attribute-target relations, to interpret over- or underperformance in attribute prediction, and to analyze attention alignment with attribute-specific regions of interest. The framework is fully customizable, supporting variations in dataset complexity, target definitions, class balance, and beyond. With complete ground truth information, FunnyNodules provides a versatile foundation for developing, benchmarking, and conducting in-depth analyses of explainable AI methods in medical image analysis.",cs.CV,2025-11-19 14:37:49+00:00,densely annotated medical image datasets capture diagnostic label also underlying reasoning behind diagnosis scarce reasoningrelated annotation essential developing evaluating explainable ai xai model reason similarly radiologist making correct prediction right reason address gap introduce funnynodules fully parameterized synthetic dataset designed systematic analysis attributebased reasoning medical ai model dataset generates abstract lung nodulelike shape controllable visual attribute roundness margin sharpness spiculation target class derived predefined attribute combination allowing full control decision rule link attribute diagnostic class demonstrate funnynodules used modelagnostic evaluation assess whether model learn correct attributetarget relation interpret underperformance attribute prediction analyze attention alignment attributespecific region interest framework fully customizable supporting variation dataset complexity target definition class balance beyond complete ground truth information funnynodules provides versatile foundation developing benchmarking conducting indepth analysis explainable ai method medical image analysis,0,"ultrasound, elastography"
RS-CA-HSICT: A Residual and Spatial Channel Augmented CNN Transformer Framework for Monkeypox Detection,"Rashid Iqbal, Saddam Hussain Khan","This work proposes a hybrid deep learning approach, namely Residual and Spatial Learning based Channel Augmented Integrated CNN-Transformer architecture, that leverages the strengths of CNN and Transformer towards enhanced MPox detection. The proposed RS-CA-HSICT framework is composed of an HSICT block, a residual CNN module, a spatial CNN block, and a CA, which enhances the diverse feature space, detailed lesion information, and long-range dependencies. The new HSICT module first integrates an abstract representation of the stem CNN and customized ICT blocks for efficient multihead attention and structured CNN layers with homogeneous (H) and structural (S) operations. The customized ICT blocks learn global contextual interactions and local texture extraction. Additionally, H and S layers learn spatial homogeneity and fine structural details by reducing noise and modeling complex morphological variations. Moreover, inverse residual learning enhances vanishing gradient, and stage-wise resolution reduction ensures scale invariance. Furthermore, the RS-CA-HSICT framework augments the learned HSICT channels with the TL-driven Residual and Spatial CNN maps for enhanced multiscale feature space capturing global and localized structural cues, subtle texture, and contrast variations. These channels, preceding augmentation, are refined through the Channel-Fusion-and-Attention block, which preserves discriminative channels while suppressing redundant ones, thereby enabling efficient computation. Finally, the spatial attention mechanism refines pixel selection to detect subtle patterns and intra-class contrast variations in Mpox. Experimental results on both the Kaggle benchmark and a diverse MPox dataset reported classification accuracy as high as 98.30% and an F1-score of 98.13%, which outperforms the existing CNNs and ViTs.","cs.CV, cs.AI, cs.LG",2025-11-19 14:32:34+00:00,work proposes hybrid deep learning approach namely residual spatial learning based channel augmented integrated cnntransformer architecture leverage strength cnn transformer towards enhanced mpox detection proposed rscahsict framework composed hsict block residual cnn module spatial cnn block ca enhances diverse feature space detailed lesion information longrange dependency new hsict module first integrates abstract representation stem cnn customized ict block efficient multihead attention structured cnn layer homogeneous h structural operation customized ict block learn global contextual interaction local texture extraction additionally h layer learn spatial homogeneity fine structural detail reducing noise modeling complex morphological variation moreover inverse residual learning enhances vanishing gradient stagewise resolution reduction ensures scale invariance furthermore rscahsict framework augments learned hsict channel tldriven residual spatial cnn map enhanced multiscale feature space capturing global localized structural cue subtle texture contrast variation channel preceding augmentation refined channelfusionandattention block preserve discriminative channel suppressing redundant one thereby enabling efficient computation finally spatial attention mechanism refines pixel selection detect subtle pattern intraclass contrast variation mpox experimental result kaggle benchmark diverse mpox dataset reported classification accuracy high 9830 f1score 9813 outperforms existing cnns vits,8,"cnntransformer, ssmixnet"
LCS: A Learnlet-Based Sparse Framework for Blind Source Separation,"V. Bonjean, A. Gkogkou, J. L. Starck, P. Tsakalides","Blind source separation (BSS) plays a pivotal role in modern astrophysics by enabling the extraction of scientifically meaningful signals from multi-frequency observations. Traditional BSS methods, such as those relying on fixed wavelet dictionaries, enforce sparsity during component separation, but may fall short when faced with the inherent complexity of real astrophysical signals. In this work, we introduce the Learnlet Component Separator (LCS), a novel BSS framework that bridges classical sparsity-based techniques with modern deep learning. LCS utilizes the Learnlet transform: a structured convolutional neural network designed to serve as a learned, wavelet-like multiscale representation. This hybrid design preserves the interpretability and sparsity, promoting properties of wavelets while gaining the adaptability and expressiveness of learned models. The LCS algorithm integrates this learned sparse representation into an iterative source separation process, enabling effective decomposition of multi-channel observations. While conceptually inspired by sparse BSS methods, LCS introduces a learned representation layer that significantly departs from classical fixed-basis assumptions. We evaluate LCS on both synthetic and real datasets, demonstrating superior separation performance compared to state-of-the-art methods (average gain of about 5 dB on toy model examples). Our results highlight the potential of hybrid approaches that combine signal processing priors with deep learning to address the challenges of next-generation cosmological experiments.","astro-ph.IM, astro-ph.CO",2025-11-19 14:31:12+00:00,blind source separation bs play pivotal role modern astrophysics enabling extraction scientifically meaningful signal multifrequency observation traditional bs method relying fixed wavelet dictionary enforce sparsity component separation may fall short faced inherent complexity real astrophysical signal work introduce learnlet component separator lcs novel bs framework bridge classical sparsitybased technique modern deep learning lcs utilizes learnlet transform structured convolutional neural network designed serve learned waveletlike multiscale representation hybrid design preserve interpretability sparsity promoting property wavelet gaining adaptability expressiveness learned model lcs algorithm integrates learned sparse representation iterative source separation process enabling effective decomposition multichannel observation conceptually inspired sparse bs method lcs introduces learned representation layer significantly departs classical fixedbasis assumption evaluate lcs synthetic real datasets demonstrating superior separation performance compared stateoftheart method average gain 5 db toy model example result highlight potential hybrid approach combine signal processing prior deep learning address challenge nextgeneration cosmological experiment,7,"supervised, audio"
Advancing Identification method of Gamma-Ray Bursts with Data and Feature Enhancement,"Peng Zhang, Bing Li, Ren-Zhou Gui, Shao-Lin Xiong, Yu Wang, Shi-Jie Zheng, Guang-Cheng Xiao, Xiao-Bo Li, Yue Huang, Chen-Wei Wang, Jia-Cong Liu, Yan-Qiu Zhang, Wang-Chen Xue, Chao Zheng, Yue Wang","Gamma-ray bursts (GRBs) are challenging to identify due to their transient nature, complex temporal profiles, and limited observational datasets. We address this with a one-dimensional convolutional neural network integrated with an Adaptive Frequency Feature Enhancement module and physics-informed data augmentation. Our framework generates 100,000 synthetic GRB samples, expanding training data diversity and volume while preserving physical fidelity-especially for low-significance events. The model achieves 97.46% classification accuracy, outperforming all tested variants with conventional enhancement modules, highlighting enhanced domain-specific feature capture. Feature visualization shows model focuses on deep-seated morphological features and confirms the capability of extracting physically meaningful burst characteristics. Dimensionality reduction and clustering reveal GRBs with similar morphologies or progenitor origins cluster in the feature space, linking learned features to physical properties. This perhaps offers a novel diagnostic tool for identifying kilonova- and supernova-associated GRB candidates, establishing criteria to enhance multi-messenger early-warning systems. The framework aids current time-domain surveys, generalizes to other rare transients, and advances automated detection in large-volume observational data.",astro-ph.HE,2025-11-19 14:27:14+00:00,gammaray burst grbs challenging identify due transient nature complex temporal profile limited observational datasets address onedimensional convolutional neural network integrated adaptive frequency feature enhancement module physicsinformed data augmentation framework generates 100000 synthetic grb sample expanding training data diversity volume preserving physical fidelityespecially lowsignificance event model achieves 9746 classification accuracy outperforming tested variant conventional enhancement module highlighting enhanced domainspecific feature capture feature visualization show model focus deepseated morphological feature confirms capability extracting physically meaningful burst characteristic dimensionality reduction clustering reveal grbs similar morphology progenitor origin cluster feature space linking learned feature physical property perhaps offer novel diagnostic tool identifying kilonova supernovaassociated grb candidate establishing criterion enhance multimessenger earlywarning system framework aid current timedomain survey generalizes rare transient advance automated detection largevolume observational data,0,"ultrasound, elastography"
Deep Learning for Accurate Vision-based Catch Composition in Tropical Tuna Purse Seiners,"Xabier Lekunberri, Ahmad Kamal, Izaro Goienetxea, Jon Ruiz, Iñaki Quincoces, Jaime Valls Miro, Ignacio Arganda-Carreras, Jose A. Fernandes-Salvador","Purse seiners play a crucial role in tuna fishing, as approximately 69% of the world's tropical tuna is caught using this gear. All tuna Regional Fisheries Management Organizations have established minimum standards to use electronic monitoring (EM) in fisheries in addition to traditional observers. The EM systems produce a massive amount of video data that human analysts must process. Integrating artificial intelligence (AI) into their workflow can decrease that workload and improve the accuracy of the reports. However, species identification still poses significant challenges for AI, as achieving balanced performance across all species requires appropriate training data. Here, we quantify the difficulty experts face to distinguish bigeye tuna (BET, Thunnus Obesus) from yellowfin tuna (YFT, Thunnus Albacares) using images captured by EM systems. We found inter-expert agreements of 42.9% $\pm$ 35.6% for BET and 57.1% $\pm$ 35.6% for YFT. We then present a multi-stage pipeline to estimate the species composition of the catches using a reliable ground-truth dataset based on identifications made by observers on board. Three segmentation approaches are compared: Mask R-CNN, a combination of DINOv2 with SAM2, and a integration of YOLOv9 with SAM2. We found that the latest performs the best, with a validation mean average precision of 0.66 $\pm$ 0.03 and a recall of 0.88 $\pm$ 0.03. Segmented individuals are tracked using ByteTrack. For classification, we evaluate a standard multiclass classification model and a hierarchical approach, finding a superior generalization by the hierarchical. All our models were cross-validated during training and tested on fishing operations with fully known catch composition. Combining YOLOv9-SAM2 with the hierarchical classification produced the best estimations, with 84.8% of the individuals being segmented and classified with a mean average error of 4.5%.",cs.CV,2025-11-19 14:26:04+00:00,purse seiners play crucial role tuna fishing approximately 69 world tropical tuna caught using gear tuna regional fishery management organization established minimum standard use electronic monitoring em fishery addition traditional observer em system produce massive amount video data human analyst must process integrating artificial intelligence ai workflow decrease workload improve accuracy report however specie identification still pose significant challenge ai achieving balanced performance across specie requires appropriate training data quantify difficulty expert face distinguish bigeye tuna bet thunnus obesus yellowfin tuna yft thunnus albacares using image captured em system found interexpert agreement 429 pm 356 bet 571 pm 356 yft present multistage pipeline estimate specie composition catch using reliable groundtruth dataset based identification made observer board three segmentation approach compared mask rcnn combination dinov2 sam2 integration yolov9 sam2 found latest performs best validation mean average precision 066 pm 003 recall 088 pm 003 segmented individual tracked using bytetrack classification evaluate standard multiclass classification model hierarchical approach finding superior generalization hierarchical model crossvalidated training tested fishing operation fully known catch composition combining yolov9sam2 hierarchical classification produced best estimation 848 individual segmented classified mean average error 45,5,"tokenisation, tokenisers"
SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome,"Dabin Jeong, Amirhossein Vahidi, Ciro Ramírez-Suástegui, Marie Moullet, Kevin Ly, Mohammad Vali Sanian, Sebastian Birk, Yinshui Chang, Adam Boxall, Daniyal Jafree, Lloyd Steele, Vijaya Baskar MS, Muzlifah Haniffa, Mohammad Lotfollahi","Recent advances in computational pathology have leveraged vision-language models to learn joint representations of Hematoxylin and Eosin (HE) images with spatial transcriptomic (ST) profiles. However, existing approaches typically align HE tiles with their corresponding ST profiles at a single scale, overlooking fine-grained cellular structures and their spatial organization. To address this, we propose Sigmma, a multi-modal contrastive alignment framework for learning hierarchical representations of HE images and spatial transcriptome profiles across multiple scales. Sigmma introduces multi-scale contrastive alignment, ensuring that representations learned at different scales remain coherent across modalities. Furthermore, by representing cell interactions as a graph and integrating inter- and intra-subgraph relationships, our approach effectively captures cell-cell interactions, ranging from fine to coarse, within the tissue microenvironment. We demonstrate that Sigmm learns representations that better capture cross-modal correspondences, leading to an improvement of avg. 9.78\% in the gene-expression prediction task and avg. 26.93\% in the cross-modal retrieval task across datasets. We further show that it learns meaningful multi-tissue organization in downstream analyses.","cs.CV, cs.LG",2025-11-19 14:22:23+00:00,recent advance computational pathology leveraged visionlanguage model learn joint representation hematoxylin eosin image spatial transcriptomic st profile however existing approach typically align tile corresponding st profile single scale overlooking finegrained cellular structure spatial organization address propose sigmma multimodal contrastive alignment framework learning hierarchical representation image spatial transcriptome profile across multiple scale sigmma introduces multiscale contrastive alignment ensuring representation learned different scale remain coherent across modality furthermore representing cell interaction graph integrating inter intrasubgraph relationship approach effectively capture cellcell interaction ranging fine coarse within tissue microenvironment demonstrate sigmm learns representation better capture crossmodal correspondence leading improvement avg 978 geneexpression prediction task avg 2693 crossmodal retrieval task across datasets show learns meaningful multitissue organization downstream analysis,0,"ultrasound, elastography"
Insights from the ICLR Peer Review and Rebuttal Process,"Amir Hossein Kargaran, Nafiseh Nikeghbal, Jing Yang, Nedjma Ousidhoum","Peer review is a cornerstone of scientific publishing, including at premier machine learning conferences such as ICLR. As submission volumes increase, understanding the nature and dynamics of the review process is crucial for improving its efficiency, effectiveness, and the quality of published papers. We present a large-scale analysis of the ICLR 2024 and 2025 peer review processes, focusing on before- and after-rebuttal scores and reviewer-author interactions. We examine review scores, author-reviewer engagement, temporal patterns in review submissions, and co-reviewer influence effects. Combining quantitative analyses with LLM-based categorization of review texts and rebuttal discussions, we identify common strengths and weaknesses for each rating group, as well as trends in rebuttal strategies that are most strongly associated with score changes. Our findings show that initial scores and the ratings of co-reviewers are the strongest predictors of score changes during the rebuttal, pointing to a degree of reviewer influence. Rebuttals play a valuable role in improving outcomes for borderline papers, where thoughtful author responses can meaningfully shift reviewer perspectives. More broadly, our study offers evidence-based insights to improve the peer review process, guiding authors on effective rebuttal strategies and helping the community design fairer and more efficient review processes. Our code and score changes data are available at https://github.com/papercopilot/iclr-insights.","cs.CY, cs.AI",2025-11-19 14:21:52+00:00,peer review cornerstone scientific publishing including premier machine learning conference iclr submission volume increase understanding nature dynamic review process crucial improving efficiency effectiveness quality published paper present largescale analysis iclr 2024 2025 peer review process focusing afterrebuttal score reviewerauthor interaction examine review score authorreviewer engagement temporal pattern review submission coreviewer influence effect combining quantitative analysis llmbased categorization review text rebuttal discussion identify common strength weakness rating group well trend rebuttal strategy strongly associated score change finding show initial score rating coreviewers strongest predictor score change rebuttal pointing degree reviewer influence rebuttal play valuable role improving outcome borderline paper thoughtful author response meaningfully shift reviewer perspective broadly study offer evidencebased insight improve peer review process guiding author effective rebuttal strategy helping community design fairer efficient review process code score change data available httpsgithubcompapercopiloticlrinsights,1,"rescuelens, volunteer"
Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining,"Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan","As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.","cs.AI, q-fin.GN",2025-11-19 14:15:23+00:00,decentralized finance defi develops understanding user intent behind defi transaction crucial yet challenging due complex smart contract interaction multifaceted onoffchain factor opaque hex log existing method lack deep semantic insight address propose transaction intent mining tim framework tim leverage defi intent taxonomy built grounded theory multiagent large language model llm system robustly infer user intent metalevel planner dynamically coordinate domain expert decompose multiple perspectivespecific intent analysis solvable subtasks question solver handle task multimodal onoffchain data cognitive evaluator mitigates llm hallucination ensures verifiability experiment show tim significantly outperforms machine learning model single llm single agent baseline also analyze core challenge intent inference work help provide reliable understanding user motivation defi offering contextaware explanation complex blockchain activity,1,"rescuelens, volunteer"
FairEnergy: Contribution-Based Fairness meets Energy Efficiency in Federated Learning,"Ouiame Marnissi, Hajar EL Hammouti, El Houcine Bergou","Federated learning (FL) enables collaborative model training across distributed devices while preserving data privacy. However, balancing energy efficiency and fair participation while ensuring high model accuracy remains challenging in wireless edge systems due to heterogeneous resources, unequal client contributions, and limited communication capacity. To address these challenges, we propose FairEnergy, a fairness-aware energy minimization framework that integrates a contribution score capturing both the magnitude of updates and their compression ratio into the joint optimization of device selection, bandwidth allocation, and compression level. The resulting mixed-integer non-convex problem is solved by relaxing binary selection variables and applying Lagrangian decomposition to handle global bandwidth coupling, followed by per-device subproblem optimization. Experiments on non-IID data show that FairEnergy achieves higher accuracy while reducing energy consumption by up to 79\% compared to baseline strategies.",cs.LG,2025-11-19 14:11:44+00:00,federated learning fl enables collaborative model training across distributed device preserving data privacy however balancing energy efficiency fair participation ensuring high model accuracy remains challenging wireless edge system due heterogeneous resource unequal client contribution limited communication capacity address challenge propose fairenergy fairnessaware energy minimization framework integrates contribution score capturing magnitude update compression ratio joint optimization device selection bandwidth allocation compression level resulting mixedinteger nonconvex problem solved relaxing binary selection variable applying lagrangian decomposition handle global bandwidth coupling followed perdevice subproblem optimization experiment noniid data show fairenergy achieves higher accuracy reducing energy consumption 79 compared baseline strategy,2,"dynamicslearning, sgd"
TSFM in-context learning for time-series classification of bearing-health status,"Michel Tokic, Slobodan Djukanović, Anja von Beuningen, Cheng Feng","This paper introduces a classification method using in-context learning in time-series foundation models (TSFM). We show how data, which was not part of the TSFM training data corpus, can be classified without the need of finetuning the model. Examples are represented in the form of targets (class id) and covariates (data matrix) within the prompt of the model, which enables to classify an unknown covariate data pattern alongside the forecast axis through in-context learning. We apply this method to vibration data for assessing the health state of a bearing within a servo-press motor. The method transforms frequency domain reference signals into pseudo time-series patterns, generates aligned covariate and target signals, and uses the TSFM to predict probabilities how classified data corresponds to predefined labels. Leveraging the scalability of pre-trained models this method demonstrates efficacy across varied operational conditions. This marks significant progress beyond custom narrow AI solutions towards broader, AI-driven maintenance systems.","cs.LG, cs.AI",2025-11-19 14:01:12+00:00,paper introduces classification method using incontext learning timeseries foundation model tsfm show data part tsfm training data corpus classified without need finetuning model example represented form target class id covariates data matrix within prompt model enables classify unknown covariate data pattern alongside forecast axis incontext learning apply method vibration data assessing health state bearing within servopress motor method transforms frequency domain reference signal pseudo timeseries pattern generates aligned covariate target signal us tsfm predict probability classified data corresponds predefined label leveraging scalability pretrained model method demonstrates efficacy across varied operational condition mark significant progress beyond custom narrow ai solution towards broader aidriven maintenance system,3,"equipment, evi"
Gini Score under Ties and Case Weights,"Alexej Brauer, Mario V. Wüthrich","The Gini score is a popular tool in statistical modeling and machine learning for model validation and model selection. It is a purely rank based score that allows one to assess risk rankings. The Gini score for statistical modeling has mainly been used in a binary context, in which it has many equivalent reformulations such as the receiver operating characteristic (ROC) or the area under the curve (AUC). In the actuarial literature, this rank based score for binary responses has been extended to general real-valued random variables using Lorenz curves and concentration curves. While these initial concepts assume that the risk ranking is generated by a continuous distribution function, we discuss in this paper how the Gini score can be used in the case of ties in the risk ranking. Moreover, we adapt the Gini score to the common actuarial situation of having case weights.","stat.ML, cs.LG, stat.AP",2025-11-19 14:01:12+00:00,gini score popular tool statistical modeling machine learning model validation model selection purely rank based score allows one assess risk ranking gini score statistical modeling mainly used binary context many equivalent reformulations receiver operating characteristic roc area curve auc actuarial literature rank based score binary response extended general realvalued random variable using lorenz curve concentration curve initial concept assume risk ranking generated continuous distribution function discus paper gini score used case tie risk ranking moreover adapt gini score common actuarial situation case weight,5,"tokenisation, tokenisers"
Neural network-driven domain decomposition for efficient solutions to the Helmholtz equation,"Victorita Dolean, Daria Hrebenshchykova, Stéphane Lanteri, Victor Michel-Dansac","Accurately simulating wave propagation is crucial in fields such as acoustics, electromagnetism, and seismic analysis. Traditional numerical methods, like finite difference and finite element approaches, are widely used to solve governing partial differential equations (PDEs) such as the Helmholtz equation. However, these methods face significant computational challenges when applied to high-frequency wave problems in complex two-dimensional domains. This work investigates Finite Basis Physics-Informed Neural Networks (FBPINNs) and their multilevel extensions as a promising alternative. These methods leverage domain decomposition, partitioning the computational domain into overlapping sub-domains, each governed by a local neural network. We assess their accuracy and computational efficiency in solving the Helmholtz equation for the homogeneous case, demonstrating their potential to mitigate the limitations of traditional approaches.","math.NA, cs.LG",2025-11-19 13:58:32+00:00,accurately simulating wave propagation crucial field acoustic electromagnetism seismic analysis traditional numerical method like finite difference finite element approach widely used solve governing partial differential equation pdes helmholtz equation however method face significant computational challenge applied highfrequency wave problem complex twodimensional domain work investigates finite basis physicsinformed neural network fbpinns multilevel extension promising alternative method leverage domain decomposition partitioning computational domain overlapping subdomains governed local neural network assess accuracy computational efficiency solving helmholtz equation homogeneous case demonstrating potential mitigate limitation traditional approach,7,"supervised, audio"
A Dataset and Baseline for Deep Learning-Based Visual Quality Inspection in Remanufacturing,"Johannes C. Bauer, Paul Geng, Stephan Trattnig, Petr Dokládal, Rüdiger Daub","Remanufacturing describes a process where worn products are restored to like-new condition and it offers vast ecological and economic potentials. A key step is the quality inspection of disassembled components, which is mostly done manually due to the high variety of parts and defect patterns. Deep neural networks show great potential to automate such visual inspection tasks but struggle to generalize to new product variants, components, or defect patterns. To tackle this challenge, we propose a novel image dataset depicting typical gearbox components in good and defective condition from two automotive transmissions. Depending on the train-test split of the data, different distribution shifts are generated to benchmark the generalization ability of a classification model. We evaluate different models using the dataset and propose a contrastive regularization loss to enhance model robustness. The results obtained demonstrate the ability of the loss to improve generalisation to unseen types of components.",cs.CV,2025-11-19 13:56:33+00:00,remanufacturing describes process worn product restored likenew condition offer vast ecological economic potential key step quality inspection disassembled component mostly done manually due high variety part defect pattern deep neural network show great potential automate visual inspection task struggle generalize new product variant component defect pattern tackle challenge propose novel image dataset depicting typical gearbox component good defective condition two automotive transmission depending traintest split data different distribution shift generated benchmark generalization ability classification model evaluate different model using dataset propose contrastive regularization loss enhance model robustness result obtained demonstrate ability loss improve generalisation unseen type component,3,"equipment, evi"
"Small Language Models for Phishing Website Detection: Cost, Performance, and Privacy Trade-Offs","Georg Goldenits, Philip Koenig, Sebastian Raubitzek, Andreas Ekelhart","Phishing websites pose a major cybersecurity threat, exploiting unsuspecting users and causing significant financial and organisational harm. Traditional machine learning approaches for phishing detection often require extensive feature engineering, continuous retraining, and costly infrastructure maintenance. At the same time, proprietary large language models (LLMs) have demonstrated strong performance in phishing-related classification tasks, but their operational costs and reliance on external providers limit their practical adoption in many business environments. This paper investigates the feasibility of small language models (SLMs) for detecting phishing websites using only their raw HTML code. A key advantage of these models is that they can be deployed on local infrastructure, providing organisations with greater control over data and operations. We systematically evaluate 15 commonly used Small Language Models (SLMs), ranging from 1 billion to 70 billion parameters, benchmarking their classification accuracy, computational requirements, and cost-efficiency. Our results highlight the trade-offs between detection performance and resource consumption, demonstrating that while SLMs underperform compared to state-of-the-art proprietary LLMs, they can still provide a viable and scalable alternative to external LLM services. By presenting a comparative analysis of costs and benefits, this work lays the foundation for future research on the adaptation, fine-tuning, and deployment of SLMs in phishing detection systems, aiming to balance security effectiveness and economic practicality.","cs.CR, cs.AI",2025-11-19 13:45:07+00:00,phishing website pose major cybersecurity threat exploiting unsuspecting user causing significant financial organisational harm traditional machine learning approach phishing detection often require extensive feature engineering continuous retraining costly infrastructure maintenance time proprietary large language model llm demonstrated strong performance phishingrelated classification task operational cost reliance external provider limit practical adoption many business environment paper investigates feasibility small language model slms detecting phishing website using raw html code key advantage model deployed local infrastructure providing organisation greater control data operation systematically evaluate 15 commonly used small language model slms ranging 1 billion 70 billion parameter benchmarking classification accuracy computational requirement costefficiency result highlight tradeoff detection performance resource consumption demonstrating slms underperform compared stateoftheart proprietary llm still provide viable scalable alternative external llm service presenting comparative analysis cost benefit work lay foundation future research adaptation finetuning deployment slms phishing detection system aiming balance security effectiveness economic practicality,1,"rescuelens, volunteer"
Representation Space Constrained Learning with Modality Decoupling for Multimodal Object Detection,"YiKang Shao, Tao Shi","Multimodal object detection has attracted significant attention in both academia and industry for its enhanced robustness. Although numerous studies have focused on improving modality fusion strategies, most neglect fusion degradation, and none provide a theoretical analysis of its underlying causes. To fill this gap, this paper presents a systematic theoretical investigation of fusion degradation in multimodal detection and identifies two key optimization deficiencies: (1) the gradients of unimodal branch backbones are severely suppressed under multimodal architectures, resulting in under-optimization of the unimodal branches; (2) disparities in modality quality cause weaker modalities to experience stronger gradient suppression, which in turn results in imbalanced modality learning. To address these issues, this paper proposes a Representation Space Constrained Learning with Modality Decoupling (RSC-MD) method, which consists of two modules. The RSC module and the MD module are designed to respectively amplify the suppressed gradients and eliminate inter-modality coupling interference as well as modality imbalance, thereby enabling the comprehensive optimization of each modality-specific backbone. Extensive experiments conducted on the FLIR, LLVIP, M3FD, and MFAD datasets demonstrate that the proposed method effectively alleviates fusion degradation and achieves state-of-the-art performance across multiple benchmarks. The code and training procedures will be released at https://github.com/yikangshao/RSC-MD.",cs.CV,2025-11-19 13:41:27+00:00,multimodal object detection attracted significant attention academia industry enhanced robustness although numerous study focused improving modality fusion strategy neglect fusion degradation none provide theoretical analysis underlying cause fill gap paper present systematic theoretical investigation fusion degradation multimodal detection identifies two key optimization deficiency 1 gradient unimodal branch backbone severely suppressed multimodal architecture resulting underoptimization unimodal branch 2 disparity modality quality cause weaker modality experience stronger gradient suppression turn result imbalanced modality learning address issue paper proposes representation space constrained learning modality decoupling rscmd method consists two module rsc module md module designed respectively amplify suppressed gradient eliminate intermodality coupling interference well modality imbalance thereby enabling comprehensive optimization modalityspecific backbone extensive experiment conducted flir llvip m3fd mfad datasets demonstrate proposed method effectively alleviates fusion degradation achieves stateoftheart performance across multiple benchmark code training procedure released httpsgithubcomyikangshaorscmd,8,"cnntransformer, ssmixnet"
Towards Understanding Layer Contributions in Tabular In-Context Learning Models,"Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger","Despite the architectural similarities between tabular in-context learning (ICL) models and large language models (LLMs), little is known about how individual layers contribute to tabular prediction. In this paper, we investigate how the latent spaces evolve across layers in tabular ICL models, identify potential redundant layers, and compare these dynamics with those observed in LLMs. We analyze TabPFN and TabICL through the ""layers as painters"" perspective, finding that only subsets of layers share a common representational language, suggesting structural redundancy and offering opportunities for model compression and improved interpretability.","cs.LG, cs.AI",2025-11-19 13:39:30+00:00,despite architectural similarity tabular incontext learning icl model large language model llm little known individual layer contribute tabular prediction paper investigate latent space evolve across layer tabular icl model identify potential redundant layer compare dynamic observed llm analyze tabpfn tabicl layer painter perspective finding subset layer share common representational language suggesting structural redundancy offering opportunity model compression improved interpretability,1,"rescuelens, volunteer"
LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering,"Yuanjie Zhu, Liangwei Yang, Ke Xu, Weizhi Zhang, Zihe Song, Jindong Wang, Philip S. Yu","Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.",cs.CL,2025-11-19 13:22:08+00:00,large language model llm reshaping unsupervised learning offering unprecedented ability perform text clustering based deep semantic understanding however direct application fundamentally limited lack stateful memory iterative refinement difficulty managing cluster granularity result existing method often rely complex pipeline external module sacrificing truly endtoend approach introduce llmmemcluster novel framework reconceptualizes clustering fully llmnative task leverage dynamic memory instill state awareness dualprompt strategy enable model reason determine number cluster evaluated several benchmark datasets tuningfree framework significantly consistently outperforms strong baseline llmmemcluster present effective interpretable truly endtoend paradigm llmbased text clustering,4,"forgetting, memoryintensive"
Singular Learning Theory for Factor Analysis,"Mathias Drton, Elizabeth Gross, Dimitra Kosta, Anton Leykin, Seth Sullivant, Daniel Windisch","Watanabe's singular learning theory provides a framework for asymptotic analysis of Bayesian model selection for statistical models with singularities, where traditional statistical regularity assumptions fail. Learning coefficients, also known as real log canonical thresholds, play a central role in singular learning, as they govern the asymptotic behavior of Bayesian marginal likelihood integrals in settings where the Laplace approximations used for regular statistical models are not applicable. Learning coefficients are algebraic invariants that quantify the geometric complexity of a model and reveal how the singular structure impacts the model's generalization properties. In this paper, we apply algebraic methods to study the learning coefficients of factor analysis models, which are widely used latent variable models for continuously distributed data. Our main results provide a general upper bound for the learning coefficients as well as exact formulas for specific cases.","math.ST, math.AG",2025-11-19 13:18:29+00:00,watanabes singular learning theory provides framework asymptotic analysis bayesian model selection statistical model singularity traditional statistical regularity assumption fail learning coefficient also known real log canonical threshold play central role singular learning govern asymptotic behavior bayesian marginal likelihood integral setting laplace approximation used regular statistical model applicable learning coefficient algebraic invariant quantify geometric complexity model reveal singular structure impact model generalization property paper apply algebraic method study learning coefficient factor analysis model widely used latent variable model continuously distributed data main result provide general upper bound learning coefficient well exact formula specific case,2,"dynamicslearning, sgd"
D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models,"Wenlun Zhang, Yunshan Zhong, Zihao Ding, Xinyu Li, Kentaro Yoshioka","Data-Free Quantization (DFQ) offers a practical solution for model compression without requiring access to real data, making it particularly attractive in privacy-sensitive scenarios. While DFQ has shown promise for unimodal models, its extension to Vision-Language Models such as Contrastive Language-Image Pre-training (CLIP) models remains underexplored. In this work, we reveal that directly applying existing DFQ techniques to CLIP results in substantial performance degradation due to two key limitations: insufficient semantic content and low intra-image diversity in synthesized samples. To tackle these challenges, we propose D4C, the first DFQ framework tailored for CLIP. D4C synthesizes semantically rich and structurally diverse pseudo images through three key components: (1) Prompt-Guided Semantic Injection aligns generated images with real-world semantics using text prompts; (2) Structural Contrastive Generation reproduces compositional structures of natural images by leveraging foreground-background contrastive synthesis; and (3) Perturbation-Aware Enhancement applies controlled perturbations to improve sample diversity and robustness. These components jointly empower D4C to synthesize images that are both semantically informative and structurally diverse, effectively bridging the performance gap of DFQ on CLIP. Extensive experiments validate the effectiveness of D4C, showing significant performance improvements on various bit-widths and models. For example, under the W4A8 setting with CLIP ResNet-50 and ViT-B/32, D4C achieves Top-1 accuracy improvement of 12.4% and 18.9% on CIFAR-10, 6.8% and 19.7% on CIFAR-100, and 1.4% and 5.7% on ImageNet-1K in zero-shot classification, respectively.","cs.CV, cs.LG",2025-11-19 13:08:25+00:00,datafree quantization dfq offer practical solution model compression without requiring access real data making particularly attractive privacysensitive scenario dfq shown promise unimodal model extension visionlanguage model contrastive languageimage pretraining clip model remains underexplored work reveal directly applying existing dfq technique clip result substantial performance degradation due two key limitation insufficient semantic content low intraimage diversity synthesized sample tackle challenge propose d4c first dfq framework tailored clip d4c synthesizes semantically rich structurally diverse pseudo image three key component 1 promptguided semantic injection aligns generated image realworld semantics using text prompt 2 structural contrastive generation reproduces compositional structure natural image leveraging foregroundbackground contrastive synthesis 3 perturbationaware enhancement applies controlled perturbation improve sample diversity robustness component jointly empower d4c synthesize image semantically informative structurally diverse effectively bridging performance gap dfq clip extensive experiment validate effectiveness d4c showing significant performance improvement various bitwidths model example w4a8 setting clip resnet50 vitb32 d4c achieves top1 accuracy improvement 124 189 cifar10 68 197 cifar100 14 57 imagenet1k zeroshot classification respectively,4,"forgetting, memoryintensive"
Proximal Approximate Inference in State-Space Models,"Hany Abdulsamad, Ángel F. García-Fernández, Simo Särkkä","We present a class of algorithms for state estimation in nonlinear, non-Gaussian state-space models. Our approach is based on a variational Lagrangian formulation that casts Bayesian inference as a sequence of entropic trust-region updates subject to dynamic constraints. This framework gives rise to a family of forward-backward algorithms, whose structure is determined by the chosen factorization of the variational posterior. By focusing on Gauss--Markov approximations, we derive recursive schemes with favorable computational complexity. For general nonlinear, non-Gaussian models we close the recursions using generalized statistical linear regression and Fourier--Hermite moment matching.","cs.LG, stat.ME",2025-11-19 13:06:08+00:00,present class algorithm state estimation nonlinear nongaussian statespace model approach based variational lagrangian formulation cast bayesian inference sequence entropic trustregion update subject dynamic constraint framework give rise family forwardbackward algorithm whose structure determined chosen factorization variational posterior focusing gaussmarkov approximation derive recursive scheme favorable computational complexity general nonlinear nongaussian model close recursion using generalized statistical linear regression fourierhermite moment matching,2,"dynamicslearning, sgd"
IPR-1: Interactive Physical Reasoner,"Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li","Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.","cs.AI, cs.CV",2025-11-19 13:04:44+00:00,human learn observing interacting environment internalizing physic causality aim ask whether agent similarly acquire humanlike reasoning interaction keep improving experience study gametounseen g2u setting curating 1000 heterogeneous game diverse physical causal mechanism evaluate three humanlike level survival curiosity utility primitive intuition goaldriven reasoning analysis reveals complementary failure vlmvla agent reason lack lookahead interactive setting world model imagine imitate visual pattern rather analyze physic causality therefore propose ipr interactive physical reasoner using worldmodel rollouts score reinforce vlms policy introduce physcode physicscentric action code aligning semantic intent dynamic provide shared action space prediction reasoning pretrained 1000 game ipr performs robustly three level match gpt5 overall surpasses curiosity find performance improves training game interaction step model also zeroshot transfer unseen game result support physicscentric interaction path steadily improving physical reasoning,1,"rescuelens, volunteer"
Controlling False Positives in Image Segmentation via Conformal Prediction,"Luca Mossina, Corentin Friedrich","Reliable semantic segmentation is essential for clinical decision making, yet deep models rarely provide explicit statistical guarantees on their errors. We introduce a simple post-hoc framework that constructs confidence masks with distribution-free, image-level control of false-positive predictions. Given any pretrained segmentation model, we define a nested family of shrunken masks obtained either by increasing the score threshold or by applying morphological erosion. A labeled calibration set is used to select a single shrink parameter via conformal prediction, ensuring that, for new images that are exchangeable with the calibration data, the proportion of false positives retained in the confidence mask stays below a user-specified tolerance with high probability. The method is model-agnostic, requires no retraining, and provides finite-sample guarantees regardless of the underlying predictor. Experiments on a polyp-segmentation benchmark demonstrate target-level empirical validity. Our framework enables practical, risk-aware segmentation in settings where over-segmentation can have clinical consequences. Code at https://github.com/deel-ai-papers/conseco.","cs.CV, cs.LG",2025-11-19 13:02:50+00:00,reliable semantic segmentation essential clinical decision making yet deep model rarely provide explicit statistical guarantee error introduce simple posthoc framework construct confidence mask distributionfree imagelevel control falsepositive prediction given pretrained segmentation model define nested family shrunken mask obtained either increasing score threshold applying morphological erosion labeled calibration set used select single shrink parameter via conformal prediction ensuring new image exchangeable calibration data proportion false positive retained confidence mask stay userspecified tolerance high probability method modelagnostic requires retraining provides finitesample guarantee regardless underlying predictor experiment polypsegmentation benchmark demonstrate targetlevel empirical validity framework enables practical riskaware segmentation setting oversegmentation clinical consequence code httpsgithubcomdeelaipapersconseco,0,"ultrasound, elastography"
Communication-Pipelined Split Federated Learning for Foundation Model Fine-Tuning in UAV Networks,"Zizhen Zhou, Ying-Chang Liang, Yanyu Cheng, Wei Yang Bryan Lim","Deploying foundation models (FMs) on uncrewed aerial vehicles (UAVs) promises broad ``low-altitude economy'' applications. Split federated learning (SFL)-based fine-tuning leverages distributed data while keeping raw data local and reduces client-side burden by partitioning the model between client and server. However, the per-round training latency is dominated by stragglers. Training paradigms featuring parallel gradient transmission (GT) allocate dedicated portions of downlink communication resources to each client. They may leave resources idle and suffer from prolonged GT latency, especially in UAV networks, where the communication latency typically far exceeds the computation latency. To address this, we propose a sequential GT paradigm, where the server dedicates all downlink resources for the current GT. We further propose communication-pipelined SFL (CPSFL), characterized by downlink GT priority scheduling and intra-round asynchronous training. We investigate CPSFL-based LoRA fine-tuning of FMs in UAV networks and formulate an optimization problem to minimize a weighted sum of per-round training latency and worst-case client energy consumption by optimizing the split point selection (SPS) and the computing and communication resource allocation (CCRA) (the uplink bandwidth allocation and the server computing frequency allocation). To solve this problem, we develop an attention-based deep reinforcement learning (DRL) framework, where the base station agent decides the split point and the CCRA in each round by leveraging previous round information, including UAV trajectories. Simulation results show that the proposed DRL-based CPSFL scheme outperforms the parallel GT benchmarks, the ablation variants, the fixed CCRA scheme, while approaching the best fixed-SPS scheme.",cs.IT,2025-11-19 12:58:25+00:00,deploying foundation model fm uncrewed aerial vehicle uavs promise broad lowaltitude economy application split federated learning sflbased finetuning leverage distributed data keeping raw data local reduces clientside burden partitioning model client server however perround training latency dominated straggler training paradigm featuring parallel gradient transmission gt allocate dedicated portion downlink communication resource client may leave resource idle suffer prolonged gt latency especially uav network communication latency typically far exceeds computation latency address propose sequential gt paradigm server dedicates downlink resource current gt propose communicationpipelined sfl cpsfl characterized downlink gt priority scheduling intraround asynchronous training investigate cpsflbased lora finetuning fm uav network formulate optimization problem minimize weighted sum perround training latency worstcase client energy consumption optimizing split point selection sps computing communication resource allocation ccra uplink bandwidth allocation server computing frequency allocation solve problem develop attentionbased deep reinforcement learning drl framework base station agent decides split point ccra round leveraging previous round information including uav trajectory simulation result show proposed drlbased cpsfl scheme outperforms parallel gt benchmark ablation variant fixed ccra scheme approaching best fixedsps scheme,1,"rescuelens, volunteer"
Mechanistic study of mixed lithium halides solid state electrolytes,"Davide Tisi, Sergey Pozdnyakov, Michele Ceriotti","Lithium halides with the general formula Li$_x$M$_y$X$_6$, where M indicates transition metal ions and X halide anions are very actively studied as solid-state electrolytes, because of relatively low cost, high stability and Li conductivity. The structure and properties of these halide-based solid electrolytes (HSE) can be tuned by alloying, e.g. using different halides and/or transition metals simultaneously. The large chemical space is difficult to sample by experiments, making simulations based on broadly applicable machine-learning interatomic potentials (MLIPs) a promising approach to elucidate structure-property relations, and facilitate the design of better-performing compositions. Here we focus on the Li$_3$YCl$_{6x}$Br$_{6(1-x)}$ system, for which reliable experimental data exists, and use the recently-developed PET-MAD universal MLIP to investigate the structure of the alloy, the interplay of crystalline lattice, volume and chemical composition, and its effect on Li conductivity. We find that the distribution of Cl and Br atoms is only weakly correlated, and that the primary effect of alloying is to modulate the lattice parameter -- although it can also trigger transition between different lattice symmetries. By comparing constant-volume and constant-pressure simulations, we disentangle the effect of lattice parameter and chemical composition on the conductivity, finding that the two effects compensate each other, reducing the overall dependency of conductivity on alloy composition. We also study the effect of Y-In metal substitution finding a small increase in the conductivity for the C2/m phase at 25\% In content, and an overall higher conductivity for the P$\bar{3}$m1 phase.","cond-mat.mtrl-sci, cond-mat.dis-nn, physics.atom-ph, physics.chem-ph",2025-11-19 12:56:57+00:00,lithium halide general formula li_xm_yx_6 indicates transition metal ion x halide anion actively studied solidstate electrolyte relatively low cost high stability li conductivity structure property halidebased solid electrolyte hse tuned alloying eg using different halide andor transition metal simultaneously large chemical space difficult sample experiment making simulation based broadly applicable machinelearning interatomic potential mlips promising approach elucidate structureproperty relation facilitate design betterperforming composition focus li_3ycl_6xbr_61x system reliable experimental data exists use recentlydeveloped petmad universal mlip investigate structure alloy interplay crystalline lattice volume chemical composition effect li conductivity find distribution cl br atom weakly correlated primary effect alloying modulate lattice parameter although also trigger transition different lattice symmetry comparing constantvolume constantpressure simulation disentangle effect lattice parameter chemical composition conductivity finding two effect compensate reducing overall dependency conductivity alloy composition also study effect yin metal substitution finding small increase conductivity c2m phase 25 content overall higher conductivity pbar3m1 phase,3,"equipment, evi"
"One algebra for all : Geometric Algebra methods for neurosymbolic XR scene authoring, animation and neural rendering","Manos Kamarianakis, Antonis Protopsaltis, George Papagiannakis","This position paper delves into the transformative role of Geometric Algebra (GA) in advancing specific areas of Computer Graphics (CG) and Extended Reality (XR), particularly in character animation, rendering, rigging, neural rendering, and generative AI-driven scene editing. Common CG algorithms require handling rotations, translations, and dilations (uniform scalings) in operations such as object rendering, rigged model animation, soft-body deformation, and XR simulations. Traditional representation forms - such as matrices, quaternions, and vectors - often introduce limitations in precision and performance. Recent breakthroughs in the use of GA suggest it can significantly enhance these processes by encapsulating geometric forms and transformations into uniform algebraic expressions, which maintain critical geometric properties throughout multi-step transformations. Furthermore, we explore how GA can serve as a unifying mathematical substrate for neurosymbolic XR scene authoring, bridging learned neural representations and explicit geometric reasoning. This paper outlines how GA-based approaches can improve the fidelity of rigged character animations, enhance soft-body simulations, streamline real-time rendering, and optimize neural and generative AI scene editing. GA offers a coherent and efficient framework for these processes, resulting in superior visual outcomes and computational efficiency, particularly in XR environments.",cs.GR,2025-11-19 12:53:37+00:00,position paper delf transformative role geometric algebra ga advancing specific area computer graphic cg extended reality xr particularly character animation rendering rigging neural rendering generative aidriven scene editing common cg algorithm require handling rotation translation dilation uniform scaling operation object rendering rigged model animation softbody deformation xr simulation traditional representation form matrix quaternion vector often introduce limitation precision performance recent breakthrough use ga suggest significantly enhance process encapsulating geometric form transformation uniform algebraic expression maintain critical geometric property throughout multistep transformation furthermore explore ga serve unifying mathematical substrate neurosymbolic xr scene authoring bridging learned neural representation explicit geometric reasoning paper outline gabased approach improve fidelity rigged character animation enhance softbody simulation streamline realtime rendering optimize neural generative ai scene editing ga offer coherent efficient framework process resulting superior visual outcome computational efficiency particularly xr environment,4,"forgetting, memoryintensive"
ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation,"Simon Boeder, Fabian Gigengack, Simon Roesler, Holger Caesar, Benjamin Risse","Recent progress in self- and weakly supervised occupancy estimation has largely relied on 2D projection or rendering-based supervision, which suffers from geometric inconsistencies and severe depth bleeding. We thus introduce ShelfOcc, a vision-only method that overcomes these limitations without relying on LiDAR. ShelfOcc brings supervision into native 3D space by generating metrically consistent semantic voxel labels from video, enabling true 3D supervision without any additional sensors or manual 3D annotations. While recent vision-based 3D geometry foundation models provide a promising source of prior knowledge, they do not work out of the box as a prediction due to sparse or noisy and inconsistent geometry, especially in dynamic driving scenes. Our method introduces a dedicated framework that mitigates these issues by filtering and accumulating static geometry consistently across frames, handling dynamic content and propagating semantic information into a stable voxel representation. This data-centric shift in supervision for weakly/shelf-supervised occupancy estimation allows the use of essentially any SOTA occupancy model architecture without relying on LiDAR data. We argue that such high-quality supervision is essential for robust occupancy learning and constitutes an important complementary avenue to architectural innovation. On the Occ3D-nuScenes benchmark, ShelfOcc substantially outperforms all previous weakly/shelf-supervised methods (up to a 34% relative improvement), establishing a new data-driven direction for LiDAR-free 3D scene understanding.",cs.CV,2025-11-19 12:44:13+00:00,recent progress self weakly supervised occupancy estimation largely relied 2d projection renderingbased supervision suffers geometric inconsistency severe depth bleeding thus introduce shelfocc visiononly method overcomes limitation without relying lidar shelfocc brings supervision native 3d space generating metrically consistent semantic voxel label video enabling true 3d supervision without additional sensor manual 3d annotation recent visionbased 3d geometry foundation model provide promising source prior knowledge work box prediction due sparse noisy inconsistent geometry especially dynamic driving scene method introduces dedicated framework mitigates issue filtering accumulating static geometry consistently across frame handling dynamic content propagating semantic information stable voxel representation datacentric shift supervision weaklyshelfsupervised occupancy estimation allows use essentially sota occupancy model architecture without relying lidar data argue highquality supervision essential robust occupancy learning constitutes important complementary avenue architectural innovation occ3dnuscenes benchmark shelfocc substantially outperforms previous weaklyshelfsupervised method 34 relative improvement establishing new datadriven direction lidarfree 3d scene understanding,8,"cnntransformer, ssmixnet"
EVA-Net: Interpretable Brain Age Prediction via Continuous Aging Prototypes from EEG,"Kunyu Zhang, Mingxuan Wang, Xiangjie Shi, Haoxing Xu, Chao Zhang","The brain age is a key indicator of brain health. While electroencephalography (EEG) is a practical tool for this task, existing models struggle with the common challenge of imperfect medical data, such as learning a ``normal'' baseline from weakly supervised, healthy-only cohorts. This is a critical anomaly detection task for identifying disease, but standard models are often black boxes lacking an interpretable structure. We propose EVA-Net, a novel framework that recasts brain age as an interpretable anomaly detection problem. EVA-Net uses an efficient, sparsified-attention Transformer to model long EEG sequences. To handle noise and variability in imperfect data, it employs a Variational Information Bottleneck to learn a robust, compressed representation. For interpretability, this representation is aligned to a continuous prototype network that explicitly learns the normative healthy aging manifold. Trained on 1297 healthy subjects, EVA-Net achieves state-of-the-art accuracy. We validated its anomaly detection capabilities on an unseen cohort of 27 MCI and AD patients. This pathological group showed significantly higher brain-age gaps and a novel Prototype Alignment Error, confirming their deviation from the healthy manifold. EVA-Net provides an interpretable framework for healthcare intelligence using imperfect medical data.",cs.LG,2025-11-19 12:39:19+00:00,brain age key indicator brain health electroencephalography eeg practical tool task existing model struggle common challenge imperfect medical data learning normal baseline weakly supervised healthyonly cohort critical anomaly detection task identifying disease standard model often black box lacking interpretable structure propose evanet novel framework recasts brain age interpretable anomaly detection problem evanet us efficient sparsifiedattention transformer model long eeg sequence handle noise variability imperfect data employ variational information bottleneck learn robust compressed representation interpretability representation aligned continuous prototype network explicitly learns normative healthy aging manifold trained 1297 healthy subject evanet achieves stateoftheart accuracy validated anomaly detection capability unseen cohort 27 mci ad patient pathological group showed significantly higher brainage gap novel prototype alignment error confirming deviation healthy manifold evanet provides interpretable framework healthcare intelligence using imperfect medical data,0,"ultrasound, elastography"
Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models,"Haidong Kang, Lihong Lin, Enneng Yang, Hongning Dai, Hao Wang","Large language models (LLMs) have achieved remarkable performance on a wide range of tasks, hindering real-world deployment due to their massive size. Existing pruning methods (e.g., Wanda) tailored for LLMs rely heavily on manual design pruning algorithms, thereby leading to \textit{huge labor costs} and \textit{requires expert knowledge}. Furthermore, we are the first to identify the serious \textit{outlier value issue} behind dramatic performance degradation under high pruning ratios that are caused by uniform sparsity, raising an additional concern about how to design adaptive pruning sparsity ideal for LLMs. Can LLMs prune by themselves? In this work, we introduce an affirmative answer by proposing a novel pruning method called \textbf{AutoPrune}, which first overcomes expert knowledge limits by leveraging LLMs to design optimal pruning algorithms for themselves automatically without any expert knowledge. Specifically, to mitigate the black-box nature of LLMs, we propose a Graph-driven Chain-of-Thought (GCoT) to optimize prompts, significantly enhancing the reasoning process in learning the pruning algorithm and enabling us to generate pruning algorithms with superior performance and interpretability in the next generation. Finally, grounded in insights of outlier value issue, we introduce Skew-aware Dynamic Sparsity Allocation (SDSA) to overcome the outlier value issue, mitigating performance degradation under high pruning ratios. We conduct extensive experiments on mainstream LLMs benchmarks, demonstrating the superiority of AutoPrune, which consistently excels state-of-the-art competitors. The code is available at: https://anonymous.4open.science/r/AutoPrune.",cs.CV,2025-11-19 12:38:21+00:00,large language model llm achieved remarkable performance wide range task hindering realworld deployment due massive size existing pruning method eg wanda tailored llm rely heavily manual design pruning algorithm thereby leading textithuge labor cost textitrequires expert knowledge furthermore first identify serious textitoutlier value issue behind dramatic performance degradation high pruning ratio caused uniform sparsity raising additional concern design adaptive pruning sparsity ideal llm llm prune work introduce affirmative answer proposing novel pruning method called textbfautoprune first overcomes expert knowledge limit leveraging llm design optimal pruning algorithm automatically without expert knowledge specifically mitigate blackbox nature llm propose graphdriven chainofthought gcot optimize prompt significantly enhancing reasoning process learning pruning algorithm enabling u generate pruning algorithm superior performance interpretability next generation finally grounded insight outlier value issue introduce skewaware dynamic sparsity allocation sdsa overcome outlier value issue mitigating performance degradation high pruning ratio conduct extensive experiment mainstream llm benchmark demonstrating superiority autoprune consistently excels stateoftheart competitor code available httpsanonymous4opensciencerautoprune,5,"tokenisation, tokenisers"
Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training,"Yunjiao Zhou, Xinyan Chen, Junlang Qian, Lihua Xie, Jianfei Yang","Understanding complex human activities demands the ability to decompose motion into fine-grained, semantic-aligned sub-actions. This motion grounding process is crucial for behavior analysis, embodied AI and virtual reality. Yet, most existing methods rely on dense supervision with predefined action classes, which are infeasible in open-vocabulary, real-world settings. In this paper, we propose ZOMG, a zero-shot, open-vocabulary framework that segments motion sequences into semantically meaningful sub-actions without requiring any annotations or fine-tuning. Technically, ZOMG integrates (1) language semantic partition, which leverages large language models to decompose instructions into ordered sub-action units, and (2) soft masking optimization, which learns instance-specific temporal masks to focus on frames critical to sub-actions, while maintaining intra-segment continuity and enforcing inter-segment separation, all without altering the pretrained encoder. Experiments on three motion-language datasets demonstrate state-of-the-art effectiveness and efficiency of motion grounding performance, outperforming prior methods by +8.7\% mAP on HumanML3D benchmark. Meanwhile, significant improvements also exist in downstream retrieval, establishing a new paradigm for annotation-free motion understanding.",cs.CV,2025-11-19 12:11:36+00:00,understanding complex human activity demand ability decompose motion finegrained semanticaligned subactions motion grounding process crucial behavior analysis embodied ai virtual reality yet existing method rely dense supervision predefined action class infeasible openvocabulary realworld setting paper propose zomg zeroshot openvocabulary framework segment motion sequence semantically meaningful subactions without requiring annotation finetuning technically zomg integrates 1 language semantic partition leverage large language model decompose instruction ordered subaction unit 2 soft masking optimization learns instancespecific temporal mask focus frame critical subactions maintaining intrasegment continuity enforcing intersegment separation without altering pretrained encoder experiment three motionlanguage datasets demonstrate stateoftheart effectiveness efficiency motion grounding performance outperforming prior method 87 map humanml3d benchmark meanwhile significant improvement also exist downstream retrieval establishing new paradigm annotationfree motion understanding,9,"visionlanguageaction, geolocalization"
Terra Nova: A Comprehensive Challenge Environment for Intelligent Agents,Trevor McInroe,"We introduce Terra Nova, a new comprehensive challenge environment (CCE) for reinforcement learning (RL) research inspired by Civilization V. A CCE is a single environment in which multiple canonical RL challenges (e.g., partial observability, credit assignment, representation learning, enormous action spaces, etc.) arise simultaneously. Mastery therefore demands integrated, long-horizon understanding across many interacting variables. We emphasize that this definition excludes challenges that only aggregate unrelated tasks in independent, parallel streams (e.g., learning to play all Atari games at once). These aggregated multitask benchmarks primarily asses whether an agent can catalog and switch among unrelated policies rather than test an agent's ability to perform deep reasoning across many interacting challenges.",cs.AI,2025-11-19 12:10:10+00:00,introduce terra nova new comprehensive challenge environment cce reinforcement learning rl research inspired civilization v cce single environment multiple canonical rl challenge eg partial observability credit assignment representation learning enormous action space etc arise simultaneously mastery therefore demand integrated longhorizon understanding across many interacting variable emphasize definition excludes challenge aggregate unrelated task independent parallel stream eg learning play atari game aggregated multitask benchmark primarily ass whether agent catalog switch among unrelated policy rather test agent ability perform deep reasoning across many interacting challenge,9,"visionlanguageaction, geolocalization"
QSentry: Backdoor Detection for Quantum Neural Networks via Measurement Clustering,"Shuolei Wang, Zimeng Xiao, Jinjing Shi, Heyuan Shi, Shichao Zhang, Xuelong Li","Quantum neural networks (QNNs) are an important model for implementing quantum machine learning (QML), while they demonstrate a high degree of vulnerability to backdoor attacks similar to classical networks. To address this issue, a quantum backdoor attack detection framework called QSentry is proposed, in which a quantum Measurement Clustering method is introduced to detect backdoors by identifying statistical anomalies in measurement outputs. It is demonstrated that QSentry can effectively detect anomalous distributions induced by backdoor samples with extensive experiments. It achieves a 75.8% F1 score even under a 1% poisoning rate, and further improves to 85.7% and 93.2% as the poisoning rate increases to 5% and 10%, respectively. The integration of silhouette coefficients and relative cluster size enable QSentry to precisely isolate backdoor samples, yielding estimates that closely match actual poisoning ratios. Evaluations under various quantum attack scenarios demonstrate that QSentry delivers superior robustness and accuracy compared with three state-of-the-art detection methods. This work establishes a practical and effective framework for mitigating backdoor threats in QML.",quant-ph,2025-11-19 12:08:11+00:00,quantum neural network qnns important model implementing quantum machine learning qml demonstrate high degree vulnerability backdoor attack similar classical network address issue quantum backdoor attack detection framework called qsentry proposed quantum measurement clustering method introduced detect backdoor identifying statistical anomaly measurement output demonstrated qsentry effectively detect anomalous distribution induced backdoor sample extensive experiment achieves 758 f1 score even 1 poisoning rate improves 857 932 poisoning rate increase 5 10 respectively integration silhouette coefficient relative cluster size enable qsentry precisely isolate backdoor sample yielding estimate closely match actual poisoning ratio evaluation various quantum attack scenario demonstrate qsentry delivers superior robustness accuracy compared three stateoftheart detection method work establishes practical effective framework mitigating backdoor threat qml,6,"qml, higgs"
Parameter Importance-Driven Continual Learning for Foundation Models,"Lingxiang Wang, Hainan Zhang, Zhiming Zheng","Domain-specific post-training often causes catastrophic forgetting, making foundation models lose their general reasoning ability and limiting their adaptability to dynamic real-world environments. Preserving general capabilities while acquiring downstream domain knowledge is a central challenge for large language and multimodal models. Traditional continual learning methods, such as regularization, replay and architectural isolation, suffer from poor downstream performance, reliance on inaccessible historical data, or additional parameter overhead. While recent parameter-efficient tuning (PET) methods can alleviate forgetting, their effectiveness strongly depends on the choice of parameters and update strategies. In this paper, we introduce PIECE, a Parameter Importance Estimation-based Continual Enhancement method that preserves general ability while efficiently learning domain knowledge without accessing prior training data or increasing model parameters. PIECE selectively updates only 0.1% of core parameters most relevant to new tasks, guided by two importance estimators: PIECE-F based on Fisher Information, and PIECE-S based on a second-order normalization that combines gradient and curvature information. Experiments across three language models and two multimodal models show that PIECE maintains general capabilities and achieves state-of-the-art continual learning performance across diverse downstream tasks. Our results highlight a practical path to scalable, domain-adaptive foundation models without catastrophic forgetting.","cs.LG, cs.AI",2025-11-19 12:07:53+00:00,domainspecific posttraining often cause catastrophic forgetting making foundation model lose general reasoning ability limiting adaptability dynamic realworld environment preserving general capability acquiring downstream domain knowledge central challenge large language multimodal model traditional continual learning method regularization replay architectural isolation suffer poor downstream performance reliance inaccessible historical data additional parameter overhead recent parameterefficient tuning pet method alleviate forgetting effectiveness strongly depends choice parameter update strategy paper introduce piece parameter importance estimationbased continual enhancement method preserve general ability efficiently learning domain knowledge without accessing prior training data increasing model parameter piece selectively update 01 core parameter relevant new task guided two importance estimator piecef based fisher information piece based secondorder normalization combine gradient curvature information experiment across three language model two multimodal model show piece maintains general capability achieves stateoftheart continual learning performance across diverse downstream task result highlight practical path scalable domainadaptive foundation model without catastrophic forgetting,4,"forgetting, memoryintensive"
Judicial Sentencing Prediction Based on Hybrid Models and Two-Stage Learning Algorithms,"Ruifen Dai, Xin Zheng, Fang Wang, Lei Guo","The investigation of legal judgment prediction (LJP), such as sentencing prediction, has attracted broad attention for its potential to promote judicial fairness, making the accuracy and reliability of its computation result an increasingly critical concern. In view of this, we present a new sentencing model that shares both legal logic interpretability and strong prediction capability by introducing a two-stage learning algorithm. Specifically, we first construct a hybrid model that synthesizes a mechanism model based on the main factors for sentencing with a neural network modeling possible uncertain features. We then propose a two-stage learning algorithm: First, an adaptive stochastic gradient (ASG) algorithm is used to get good estimates for the unknown parameters in the mechanistic component of the hybrid model. Then, the Adam optimizer tunes all parameters to enhance the predictive performance of the entire hybrid model. The asymptotic convergence of the ASG-based adaptive predictor is established without requiring any excitation data conditions, thereby providing a good initial parameter estimate for prediction. Based on this, the fast-converging Adam optimizer further refines the parameters to enhance overall prediction accuracy. Experiments on a real-world dataset of intentional injury cases in China show that our new hybrid model combined with our two-stage ASG-Adam algorithm, outperforms the existing related methods in sentencing prediction performance, including those based on neural networks and saturated mechanism models.",math.DS,2025-11-19 12:00:45+00:00,investigation legal judgment prediction ljp sentencing prediction attracted broad attention potential promote judicial fairness making accuracy reliability computation result increasingly critical concern view present new sentencing model share legal logic interpretability strong prediction capability introducing twostage learning algorithm specifically first construct hybrid model synthesizes mechanism model based main factor sentencing neural network modeling possible uncertain feature propose twostage learning algorithm first adaptive stochastic gradient asg algorithm used get good estimate unknown parameter mechanistic component hybrid model adam optimizer tune parameter enhance predictive performance entire hybrid model asymptotic convergence asgbased adaptive predictor established without requiring excitation data condition thereby providing good initial parameter estimate prediction based fastconverging adam optimizer refines parameter enhance overall prediction accuracy experiment realworld dataset intentional injury case china show new hybrid model combined twostage asgadam algorithm outperforms existing related method sentencing prediction performance including based neural network saturated mechanism model,5,"tokenisation, tokenisers"
CID: Measuring Feature Importance Through Counterfactual Distributions,"Eddie Conti, Álvaro Parafita, Axel Brando","Assessing the importance of individual features in Machine Learning is critical to understand the model's decision-making process. While numerous methods exist, the lack of a definitive ground truth for comparison highlights the need for alternative, well-founded measures. This paper introduces a novel post-hoc local feature importance method called Counterfactual Importance Distribution (CID). We generate two sets of positive and negative counterfactuals, model their distributions using Kernel Density Estimation, and rank features based on a distributional dissimilarity measure. This measure, grounded in a rigorous mathematical framework, satisfies key properties required to function as a valid metric. We showcase the effectiveness of our method by comparing with well-established local feature importance explainers. Our method not only offers complementary perspectives to existing approaches, but also improves performance on faithfulness metrics (both for comprehensiveness and sufficiency), resulting in more faithful explanations of the system. These results highlight its potential as a valuable tool for model analysis.",cs.LG,2025-11-19 11:57:59+00:00,assessing importance individual feature machine learning critical understand model decisionmaking process numerous method exist lack definitive ground truth comparison highlight need alternative wellfounded measure paper introduces novel posthoc local feature importance method called counterfactual importance distribution cid generate two set positive negative counterfactuals model distribution using kernel density estimation rank feature based distributional dissimilarity measure measure grounded rigorous mathematical framework satisfies key property required function valid metric showcase effectiveness method comparing wellestablished local feature importance explainers method offer complementary perspective existing approach also improves performance faithfulness metric comprehensiveness sufficiency resulting faithful explanation system result highlight potential valuable tool model analysis,5,"tokenisation, tokenisers"
The Empowerment of Science of Science by Large Language Models: New Tools and Methods,"Guoqiang Liang, Jingqian Gong, Mengxuan Li, Gege Lin, Shuo Zhang","Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.","cs.CL, cs.AI",2025-11-19 11:57:22+00:00,large language model llm exhibited exceptional capability natural language understanding generation image recognition multimodal task charting course towards agi emerging central issue global technological race manuscript conduct comprehensive review core technology support llm user standpoint including prompt engineering knowledgeenhanced retrieval augmented generation fine tuning pretraining tool learning additionally trace historical development science science scisci present forward looking perspective potential application llm within scientometric domain furthermore discusses prospect ai agent based model scientific evaluation present new research front detection knowledge graph building method llm,1,"rescuelens, volunteer"
Fidelity-Preserving Quantum Encoding for Quantum Neural Networks,"Yuhu Lu, Jinjing Shi","Efficiently encoding classical visual data into quantum states is essential for realizing practical quantum neural networks (QNNs). However, existing encoding schemes often discard spatial and semantic information when adapting high-dimensional images to the limited qubits of Noisy Intermediate-Scale Quantum (NISQ) devices. We propose a Fidelity-Preserving Quantum Encoding (FPQE) framework that performs near lossless data compression and quantum encoding. FPQE employs a convolutional encoder-decoder to learn compact multi-channel representations capable of reconstructing the original data with high fidelity, which are then mapped into quantum states through amplitude encoding. Experimental results show that FPQE performs comparably to conventional methods on simple datasets such as MNIST, while achieving clear improvements on more complex ones, outperforming PCA and pruning based encodings by up to 10.2\% accuracy on Cifar-10. The performance gain grows with data complexity, demonstrating FPQE's ability to preserve high-level structural information across diverse visual domains. By maintaining fidelity during classical to quantum transformation, FPQE establishes a scalable and hardware efficient foundation for high-quality quantum representation learning.",quant-ph,2025-11-19 11:44:39+00:00,efficiently encoding classical visual data quantum state essential realizing practical quantum neural network qnns however existing encoding scheme often discard spatial semantic information adapting highdimensional image limited qubits noisy intermediatescale quantum nisq device propose fidelitypreserving quantum encoding fpqe framework performs near lossless data compression quantum encoding fpqe employ convolutional encoderdecoder learn compact multichannel representation capable reconstructing original data high fidelity mapped quantum state amplitude encoding experimental result show fpqe performs comparably conventional method simple datasets mnist achieving clear improvement complex one outperforming pca pruning based encoding 102 accuracy cifar10 performance gain grows data complexity demonstrating fpqes ability preserve highlevel structural information across diverse visual domain maintaining fidelity classical quantum transformation fpqe establishes scalable hardware efficient foundation highquality quantum representation learning,6,"qml, higgs"
Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention,"Gabriele Calzolari, Vidya Sumathy, Christoforos Kanellakis, George Nikolakopoulos","Autonomous exploration of obstacle-rich spaces requires strategies that ensure efficiency while guaranteeing safety against collisions with obstacles. This paper investigates a novel platform-agnostic reinforcement learning framework that integrates a graph neural network-based policy for next-waypoint selection, with a safety filter ensuring safe mobility. Specifically, the neural network is trained using reinforcement learning through the Proximal Policy Optimization (PPO) algorithm to maximize exploration efficiency while minimizing safety filter interventions. Henceforth, when the policy proposes an infeasible action, the safety filter overrides it with the closest feasible alternative, ensuring consistent system behavior. In addition, this paper introduces a reward function shaped by a potential field that accounts for both the agent's proximity to unexplored regions and the expected information gain from reaching them. The proposed framework combines the adaptability of reinforcement learning-based exploration policies with the reliability provided by explicit safety mechanisms. This feature plays a key role in enabling the deployment of learning-based policies on robotic platforms operating in real-world environments. Extensive evaluations in both simulations and experiments performed in a lab environment demonstrate that the approach achieves efficient and safe exploration in cluttered spaces.",cs.RO,2025-11-19 11:37:01+00:00,autonomous exploration obstaclerich space requires strategy ensure efficiency guaranteeing safety collision obstacle paper investigates novel platformagnostic reinforcement learning framework integrates graph neural networkbased policy nextwaypoint selection safety filter ensuring safe mobility specifically neural network trained using reinforcement learning proximal policy optimization ppo algorithm maximize exploration efficiency minimizing safety filter intervention henceforth policy proposes infeasible action safety filter override closest feasible alternative ensuring consistent system behavior addition paper introduces reward function shaped potential field account agent proximity unexplored region expected information gain reaching proposed framework combine adaptability reinforcement learningbased exploration policy reliability provided explicit safety mechanism feature play key role enabling deployment learningbased policy robotic platform operating realworld environment extensive evaluation simulation experiment performed lab environment demonstrate approach achieves efficient safe exploration cluttered space,9,"visionlanguageaction, geolocalization"
Cost-Aware Prediction (CAP): An LLM-Enhanced Machine Learning Pipeline and Decision Support System for Heart Failure Mortality Prediction,"Yinan Yu, Falk Dippel, Christina E. Lundberg, Martin Lindgren, Annika Rosengren, Martin Adiels, Helen Sjöland","Objective: Machine learning (ML) predictive models are often developed without considering downstream value trade-offs and clinical interpretability. This paper introduces a cost-aware prediction (CAP) framework that combines cost-benefit analysis assisted by large language model (LLM) agents to communicate the trade-offs involved in applying ML predictions. Materials and Methods: We developed an ML model predicting 1-year mortality in patients with heart failure (N = 30,021, 22% mortality) to identify those eligible for home care. We then introduced clinical impact projection (CIP) curves to visualize important cost dimensions - quality of life and healthcare provider expenses, further divided into treatment and error costs, to assess the clinical consequences of predictions. Finally, we used four LLM agents to generate patient-specific descriptions. The system was evaluated by clinicians for its decision support value. Results: The eXtreme gradient boosting (XGB) model achieved the best performance, with an area under the receiver operating characteristic curve (AUROC) of 0.804 (95% confidence interval (CI) 0.792-0.816), area under the precision-recall curve (AUPRC) of 0.529 (95% CI 0.502-0.558) and a Brier score of 0.135 (95% CI 0.130-0.140). Discussion: The CIP cost curves provided a population-level overview of cost composition across decision thresholds, whereas LLM-generated cost-benefit analysis at individual patient-levels. The system was well received according to the evaluation by clinicians. However, feedback emphasizes the need to strengthen the technical accuracy for speculative tasks. Conclusion: CAP utilizes LLM agents to integrate ML classifier outcomes and cost-benefit analysis for more transparent and interpretable decision support.",cs.LG,2025-11-19 11:34:47+00:00,objective machine learning ml predictive model often developed without considering downstream value tradeoff clinical interpretability paper introduces costaware prediction cap framework combine costbenefit analysis assisted large language model llm agent communicate tradeoff involved applying ml prediction material method developed ml model predicting 1year mortality patient heart failure n 30021 22 mortality identify eligible home care introduced clinical impact projection cip curve visualize important cost dimension quality life healthcare provider expense divided treatment error cost assess clinical consequence prediction finally used four llm agent generate patientspecific description system evaluated clinician decision support value result extreme gradient boosting xgb model achieved best performance area receiver operating characteristic curve auroc 0804 95 confidence interval ci 07920816 area precisionrecall curve auprc 0529 95 ci 05020558 brier score 0135 95 ci 01300140 discussion cip cost curve provided populationlevel overview cost composition across decision threshold whereas llmgenerated costbenefit analysis individual patientlevels system well received according evaluation clinician however feedback emphasizes need strengthen technical accuracy speculative task conclusion cap utilizes llm agent integrate ml classifier outcome costbenefit analysis transparent interpretable decision support,0,"ultrasound, elastography"
Multi-layer Stack Ensembles for Time Series Forecasting,"Nathanael Bosch, Oleksandr Shchur, Nick Erickson, Michael Bohlke-Schneider, Caner Türkmen","Ensembling is a powerful technique for improving the accuracy of machine learning models, with methods like stacking achieving strong results in tabular tasks. In time series forecasting, however, ensemble methods remain underutilized, with simple linear combinations still considered state-of-the-art. In this paper, we systematically explore ensembling strategies for time series forecasting. We evaluate 33 ensemble models -- both existing and novel -- across 50 real-world datasets. Our results show that stacking consistently improves accuracy, though no single stacker performs best across all tasks. To address this, we propose a multi-layer stacking framework for time series forecasting, an approach that combines the strengths of different stacker models. We demonstrate that this method consistently provides superior accuracy across diverse forecasting scenarios. Our findings highlight the potential of stacking-based methods to improve AutoML systems for time series forecasting.",cs.LG,2025-11-19 11:21:00+00:00,ensembling powerful technique improving accuracy machine learning model method like stacking achieving strong result tabular task time series forecasting however ensemble method remain underutilized simple linear combination still considered stateoftheart paper systematically explore ensembling strategy time series forecasting evaluate 33 ensemble model existing novel across 50 realworld datasets result show stacking consistently improves accuracy though single stacker performs best across task address propose multilayer stacking framework time series forecasting approach combine strength different stacker model demonstrate method consistently provides superior accuracy across diverse forecasting scenario finding highlight potential stackingbased method improve automl system time series forecasting,3,"equipment, evi"
Fast Post-Hoc Confidence Fusion for 3-Class Open-Set Aerial Object Detection,"Spyridon Loukovitis, Vasileios Karampinis, Athanasios Voulodimos","Developing reliable UAV navigation systems requires robust air-to-air object detectors capable of distinguishing between objects seen during training and previously unseen objects. While many methods address closed-set detection and achieve high-confidence recognition of in-domain (ID) targets, they generally do not tackle open-set detection, which requires simultaneous handling of both ID and out-of-distribution (OOD) objects. Existing open-set approaches typically rely on a single uncertainty score with thresholding, limiting flexibility and often conflating OOD objects with background clutter. In contrast, we propose a lightweight, model-agnostic post-processing framework that explicitly separates background from unknown objects while preserving the base detector's performance. Our approach extends open-set detection beyond binary ID/OOD classification to real-time three-way classification among ID targets, OOD objects, and background. To this end, we employ a fusion scheme that aggregates multiple confidence estimates and per-detection features using a compact multilayer perceptron (MLP). Incorporating different logit variants into the MLP consistently enhances performance across both binary and three-class classification without compromising throughput. Extensive ablation and comparative experiments confirm that our method surpasses threshold-based baselines in two-class classification by an average of 2.7% AUROC, while retaining or improving open-set mAP. Furthermore, our study uniquely enables robust three-class classification, a critical capability for safe UAV navigation, where OOD objects must be actively avoided and background regions safely ignored. Comparative analysis highlights that our method surpasses competitive techniques in AUROC across datasets, while improving closed-set mAP by up to 9 points, an 18% relative gain.","cs.CV, cs.LG, cs.RO",2025-11-19 11:03:47+00:00,developing reliable uav navigation system requires robust airtoair object detector capable distinguishing object seen training previously unseen object many method address closedset detection achieve highconfidence recognition indomain id target generally tackle openset detection requires simultaneous handling id outofdistribution ood object existing openset approach typically rely single uncertainty score thresholding limiting flexibility often conflating ood object background clutter contrast propose lightweight modelagnostic postprocessing framework explicitly separate background unknown object preserving base detector performance approach extends openset detection beyond binary idood classification realtime threeway classification among id target ood object background end employ fusion scheme aggregate multiple confidence estimate perdetection feature using compact multilayer perceptron mlp incorporating different logit variant mlp consistently enhances performance across binary threeclass classification without compromising throughput extensive ablation comparative experiment confirm method surpasses thresholdbased baseline twoclass classification average 27 auroc retaining improving openset map furthermore study uniquely enables robust threeclass classification critical capability safe uav navigation ood object must actively avoided background region safely ignored comparative analysis highlight method surpasses competitive technique auroc across datasets improving closedset map 9 point 18 relative gain,5,"tokenisation, tokenisers"
"Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causal Insights on Cooking Fuel Access, Urbanization, and Carbon Emissions",Shan Shan,"Achieving Sustainable Development Goal 7 (Affordable and Clean Energy) requires not only technological innovation but also a deeper understanding of the socioeconomic factors influencing energy access and carbon emissions. While these factors are gaining attention, critical questions remain, particularly regarding how to quantify their impacts on energy systems, model their cross-domain interactions, and capture feedback dynamics in the broader context of energy transitions. To address these gaps, this study introduces ClimateAgents, an AI-based framework that combines large language models with domain-specialized agents to support hypothesis generation and scenario exploration. Leveraging 20 years of socioeconomic and emissions data from 265 economies, countries and regions, and 98 indicators drawn from the World Bank database, the framework applies a machine learning based causal inference approach to identify key determinants of carbon emissions in an evidence-based, data driven manner. The analysis highlights three primary drivers: access to clean cooking fuels in rural areas, access to clean cooking fuels in urban areas, and the percentage of population living in urban areas. These findings underscore the critical role of clean cooking technologies and urbanization patterns in shaping emission outcomes. In line with growing calls for evidence-based AI policy, ClimateAgents offers a modular and reflexive learning system that supports the generation of credible and actionable insights for policy. By integrating heterogeneous data modalities, including structured indicators, policy documents, and semantic reasoning, the framework contributes to adaptive policymaking infrastructures that can evolve with complex socio-technical challenges. This approach aims to support a shift from siloed modeling to reflexive, modular systems designed for dynamic, context-aware climate action.","cs.HC, cs.AI",2025-11-19 11:02:41+00:00,achieving sustainable development goal 7 affordable clean energy requires technological innovation also deeper understanding socioeconomic factor influencing energy access carbon emission factor gaining attention critical question remain particularly regarding quantify impact energy system model crossdomain interaction capture feedback dynamic broader context energy transition address gap study introduces climateagents aibased framework combine large language model domainspecialized agent support hypothesis generation scenario exploration leveraging 20 year socioeconomic emission data 265 economy country region 98 indicator drawn world bank database framework applies machine learning based causal inference approach identify key determinant carbon emission evidencebased data driven manner analysis highlight three primary driver access clean cooking fuel rural area access clean cooking fuel urban area percentage population living urban area finding underscore critical role clean cooking technology urbanization pattern shaping emission outcome line growing call evidencebased ai policy climateagents offer modular reflexive learning system support generation credible actionable insight policy integrating heterogeneous data modality including structured indicator policy document semantic reasoning framework contributes adaptive policymaking infrastructure evolve complex sociotechnical challenge approach aim support shift siloed modeling reflexive modular system designed dynamic contextaware climate action,1,"rescuelens, volunteer"
From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages,"Yi Peng, Hans-Martin Heyn, Jennifer Horkoff","In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.",cs.SE,2025-11-19 10:59:28+00:00,software engineering process machine learning mlenabled system integrating verifying ml component major challenge prerequisite specification ml component requirement including model data area traditional requirement engineering process face new obstacle underexplored source rerelevant information context ml documentation modelcards datasheets however uncertain extent rerelevant information extracted document study first investigates amount nature rerelevant information 20 publicly available modelcards datasheets show document contain significant amount potentially rerelevant information next evaluate effectively three established representation ear rupps template volere structure knowledge requirement result demonstrate pathway transform mlspecific knowledge structured requirement incorporating ml documentation software engineering process ml system,5,"tokenisation, tokenisers"
STREAM-VAE: Dual-Path Routing for Slow and Fast Dynamics in Vehicle Telemetry Anomaly Detection,"Kadir-Kaan Özer, René Ebeling, Markus Enzweiler","Automotive telemetry data exhibits slow drifts and fast spikes, often within the same sequence, making reliable anomaly detection challenging. Standard reconstruction-based methods, including sequence variational autoencoders (VAEs), use a single latent process and therefore mix heterogeneous time scales, which can smooth out spikes or inflate variances and weaken anomaly separation.
  In this paper, we present STREAM-VAE, a variational autoencoder for anomaly detection in automotive telemetry time-series data. Our model uses a dual-path encoder to separate slow drift and fast spike signal dynamics, and a decoder that represents transient deviations separately from the normal operating pattern. STREAM-VAE is designed for deployment, producing stable anomaly scores across operating modes for both in-vehicle monitors and backend fleet analytics.
  Experiments on an automotive telemetry dataset and the public SMD benchmark show that explicitly separating drift and spike dynamics improves robustness compared to strong forecasting, attention, graph, and VAE baselines.","cs.LG, cs.AI",2025-11-19 10:58:40+00:00,automotive telemetry data exhibit slow drift fast spike often within sequence making reliable anomaly detection challenging standard reconstructionbased method including sequence variational autoencoders vaes use single latent process therefore mix heterogeneous time scale smooth spike inflate variance weaken anomaly separation paper present streamvae variational autoencoder anomaly detection automotive telemetry timeseries data model us dualpath encoder separate slow drift fast spike signal dynamic decoder represents transient deviation separately normal operating pattern streamvae designed deployment producing stable anomaly score across operating mode invehicle monitor backend fleet analytics experiment automotive telemetry dataset public smd benchmark show explicitly separating drift spike dynamic improves robustness compared strong forecasting attention graph vae baseline,3,"equipment, evi"
Exponential Lasso: robust sparse penalization under heavy-tailed noise and outliers with exponential-type loss,The Tien Mai,"In high-dimensional statistics, the Lasso is a cornerstone method for simultaneous variable selection and parameter estimation. However, its reliance on the squared loss function renders it highly sensitive to outliers and heavy-tailed noise, potentially leading to unreliable model selection and biased estimates. To address this limitation, we introduce the Exponential Lasso, a novel robust method that integrates an exponential-type loss function within the Lasso framework. This loss function is designed to achieve a smooth trade-off between statistical efficiency under Gaussian noise and robustness against data contamination. Unlike other methods that cap the influence of large residuals, the exponential loss smoothly redescends, effectively downweighting the impact of extreme outliers while preserving near-quadratic behavior for small errors. We establish theoretical guarantees showing that the Exponential Lasso achieves strong statistical convergence rates, matching the classical Lasso under ideal conditions while maintaining its robustness in the presence of heavy-tailed contamination. Computationally, the estimator is optimized efficiently via a Majorization-Minimization (MM) algorithm that iteratively solves a series of weighted Lasso subproblems. Numerical experiments demonstrate that the proposed method is highly competitive, outperforming the classical Lasso in contaminated settings and maintaining strong performance even under Gaussian noise.
  Our method is implemented in the \texttt{R} package \texttt{heavylasso} available on Github: https://github.com/tienmt/heavylasso","stat.ML, cs.LG, stat.ME",2025-11-19 10:50:46+00:00,highdimensional statistic lasso cornerstone method simultaneous variable selection parameter estimation however reliance squared loss function render highly sensitive outlier heavytailed noise potentially leading unreliable model selection biased estimate address limitation introduce exponential lasso novel robust method integrates exponentialtype loss function within lasso framework loss function designed achieve smooth tradeoff statistical efficiency gaussian noise robustness data contamination unlike method cap influence large residual exponential loss smoothly redescends effectively downweighting impact extreme outlier preserving nearquadratic behavior small error establish theoretical guarantee showing exponential lasso achieves strong statistical convergence rate matching classical lasso ideal condition maintaining robustness presence heavytailed contamination computationally estimator optimized efficiently via majorizationminimization mm algorithm iteratively solves series weighted lasso subproblems numerical experiment demonstrate proposed method highly competitive outperforming classical lasso contaminated setting maintaining strong performance even gaussian noise method implemented textttr package textttheavylasso available github httpsgithubcomtienmtheavylasso,2,"dynamicslearning, sgd"
DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning in Human-AI Collaborative Design,"Anqi Wang, Zhengyi Li, Xin Tong, Pan Hui","Large language models (LLMs) offer powerful support for design tasks, yet their goal-oriented, single-turn responses often misalign with the nonlinear, exploratory nature of design processes. This mismatch creates a cognitive gap, limiting designers' ability to articulate evolving intentions, critically evaluate outputs, and maintain creative agency. To address these challenges, we developed DesignerlyLoop, a visual node-based system that embeds LLM reasoning chains into the design workflow. The system enables designers to externalize and curate reasoning structures, iteratively organize intentions, and interact with LLMs as dynamic cognitive engines rather than static answer providers. We conducted a within-subject study with 20 designers, combining qualitative and quantitative methods, and found that DesignerlyLoop enhanced creative reflection, design quality, and interaction experience by supporting systematic engagement with both human and machine reasoning. These findings highlight the potential of structured, interactive visualization to transform human-AI co-creation into a reflective and iterative design process.",cs.HC,2025-11-19 10:49:30+00:00,large language model llm offer powerful support design task yet goaloriented singleturn response often misalign nonlinear exploratory nature design process mismatch creates cognitive gap limiting designer ability articulate evolving intention critically evaluate output maintain creative agency address challenge developed designerlyloop visual nodebased system embeds llm reasoning chain design workflow system enables designer externalize curate reasoning structure iteratively organize intention interact llm dynamic cognitive engine rather static answer provider conducted withinsubject study 20 designer combining qualitative quantitative method found designerlyloop enhanced creative reflection design quality interaction experience supporting systematic engagement human machine reasoning finding highlight potential structured interactive visualization transform humanai cocreation reflective iterative design process,1,"rescuelens, volunteer"
BaGGLS: A Bayesian Shrinkage Framework for Interpretable Modeling of Interactions in High-Dimensional Biological Data,"Marta S. Lemanczyk, Lucas Kock, Johanna Schlimme, Nadja Klein, Bernhard Y. Renard","Biological data sets are often high-dimensional, noisy, and governed by complex interactions among sparse signals. This poses major challenges for interpretability and reliable feature selection. Tasks such as identifying motif interactions in genomics exemplify these difficulties, as only a small subset of biologically relevant features (e.g., motifs) are typically active, and their effects are often non-linear and context-dependent. While statistical approaches often result in more interpretable models, deep learning models have proven effective in modeling complex interactions and prediction accuracy, yet their black-box nature limits interpretability. We introduce BaGGLS, a flexible and interpretable probabilistic binary regression model designed for high-dimensional biological inference involving feature interactions. BaGGLS incorporates a Bayesian group global-local shrinkage prior, aligned with the group structure introduced by interaction terms. This prior encourages sparsity while retaining interpretability, helping to isolate meaningful signals and suppress noise. To enable scalable inference, we employ a partially factorized variational approximation that captures posterior skewness and supports efficient learning even in large feature spaces. In extensive simulations, we can show that BaGGLS outperforms the other methods with regard to interaction detection and is many times faster than MCMC sampling under the horseshoe prior. We also demonstrate the usefulness of BaGGLS in the context of interaction discovery from motif scanner outputs and noisy attribution scores from deep learning models. This shows that BaGGLS is a promising approach for uncovering biologically relevant interaction patterns, with potential applicability across a range of high-dimensional tasks in computational biology.","stat.ME, q-bio.GN, stat.ML",2025-11-19 10:48:30+00:00,biological data set often highdimensional noisy governed complex interaction among sparse signal pose major challenge interpretability reliable feature selection task identifying motif interaction genomics exemplify difficulty small subset biologically relevant feature eg motif typically active effect often nonlinear contextdependent statistical approach often result interpretable model deep learning model proven effective modeling complex interaction prediction accuracy yet blackbox nature limit interpretability introduce baggls flexible interpretable probabilistic binary regression model designed highdimensional biological inference involving feature interaction baggls incorporates bayesian group globallocal shrinkage prior aligned group structure introduced interaction term prior encourages sparsity retaining interpretability helping isolate meaningful signal suppress noise enable scalable inference employ partially factorized variational approximation capture posterior skewness support efficient learning even large feature space extensive simulation show baggls outperforms method regard interaction detection many time faster mcmc sampling horseshoe prior also demonstrate usefulness baggls context interaction discovery motif scanner output noisy attribution score deep learning model show baggls promising approach uncovering biologically relevant interaction pattern potential applicability across range highdimensional task computational biology,8,"cnntransformer, ssmixnet"
LaguerreNet: Advancing a Unified Solution for Heterophily and Over-smoothing with Adaptive Continuous Polynomials,Huseyin Goksu,"Spectral Graph Neural Networks (GNNs) suffer from two critical limitations: poor performance on ""heterophilic"" graphs and performance collapse at high polynomial degrees (K), known as over-smoothing. Both issues stem from the static, low-pass nature of standard filters (e.g., ChebyNet). While adaptive polynomial filters, such as the discrete MeixnerNet, have emerged as a potential unified solution, their extension to the continuous domain and stability with unbounded coefficients remain open questions. In this work, we propose `LaguerreNet`, a novel GNN filter based on continuous Laguerre polynomials. `LaguerreNet` learns the filter's spectral shape by making its core alpha parameter trainable, thereby advancing the adaptive polynomial approach. We solve the severe O(k^2) numerical instability of these unbounded polynomials using a `LayerNorm`-based stabilization technique. We demonstrate experimentally that this approach is highly effective: 1) `LaguerreNet` achieves state-of-the-art results on challenging heterophilic benchmarks. 2) It is exceptionally robust to over-smoothing, with performance peaking at K=10, an order of magnitude beyond where ChebyNet collapses.","cs.LG, eess.SP",2025-11-19 10:47:23+00:00,spectral graph neural network gnns suffer two critical limitation poor performance heterophilic graph performance collapse high polynomial degree k known oversmoothing issue stem static lowpass nature standard filter eg chebynet adaptive polynomial filter discrete meixnernet emerged potential unified solution extension continuous domain stability unbounded coefficient remain open question work propose laguerrenet novel gnn filter based continuous laguerre polynomial laguerrenet learns filter spectral shape making core alpha parameter trainable thereby advancing adaptive polynomial approach solve severe ok2 numerical instability unbounded polynomial using layernormbased stabilization technique demonstrate experimentally approach highly effective 1 laguerrenet achieves stateoftheart result challenging heterophilic benchmark 2 exceptionally robust oversmoothing performance peaking k10 order magnitude beyond chebynet collapse,7,"supervised, audio"
KrawtchoukNet: A Unified GNN Solution for Heterophily and Over-smoothing with Adaptive Bounded Polynomials,Huseyin Goksu,"Spectral Graph Neural Networks (GNNs) based on polynomial filters, such as ChebyNet, suffer from two critical limitations: 1) performance collapse on ""heterophilic"" graphs and 2) performance collapse at high polynomial degrees (K), known as over-smoothing. Both issues stem from the static, low-pass nature of standard filters. In this work, we propose `KrawtchoukNet`, a GNN filter based on the discrete Krawtchouk polynomials. We demonstrate that `KrawtchoukNet` provides a unified solution to both problems through two key design choices. First, by fixing the polynomial's domain N to a small constant (e.g., N=20), we create the first GNN filter whose recurrence coefficients are \textit{inherently bounded}, making it exceptionally robust to over-smoothing (achieving SOTA results at K=10). Second, by making the filter's shape parameter p learnable, the filter adapts its spectral response to the graph data. We show this adaptive nature allows `KrawtchoukNet` to achieve SOTA performance on challenging heterophilic benchmarks (Texas, Cornell), decisively outperforming standard GNNs like GAT and APPNP.","cs.LG, eess.SP",2025-11-19 10:47:15+00:00,spectral graph neural network gnns based polynomial filter chebynet suffer two critical limitation 1 performance collapse heterophilic graph 2 performance collapse high polynomial degree k known oversmoothing issue stem static lowpass nature standard filter work propose krawtchouknet gnn filter based discrete krawtchouk polynomial demonstrate krawtchouknet provides unified solution problem two key design choice first fixing polynomial domain n small constant eg n20 create first gnn filter whose recurrence coefficient textitinherently bounded making exceptionally robust oversmoothing achieving sota result k10 second making filter shape parameter p learnable filter adapts spectral response graph data show adaptive nature allows krawtchouknet achieve sota performance challenging heterophilic benchmark texas cornell decisively outperforming standard gnns like gat appnp,7,"supervised, audio"
On the Internal Semantics of Time-Series Foundation Models,"Atharva Pandey, Abhilash Neog, Gautam Jajoo","Time-series Foundation Models (TSFMs) have recently emerged as a universal paradigm for learning across diverse temporal domains. However, despite their empirical success, the internal mechanisms by which these models represent fundamental time-series concepts remain poorly understood. In this work, we undertake a systematic investigation of concept interpretability in TSFMs. Specifically, we examine: (i) which layers encode which concepts, (ii) whether concept parameters are linearly recoverable, (iii) how representations evolve in terms of concept disentanglement and abstraction across model depth, and (iv) how models process compositions of concepts. We systematically probe these questions using layer-wise analyses, linear recoverability tests, and representation similarity measures, providing a structured account of TSFM semantics. The resulting insights show that early layers mainly capture local, time-domain patterns (e.g., AR(1), level shifts, trends), while deeper layers encode dispersion and change-time signals, with spectral and warping factors remaining the hardest to recover linearly. In compositional settings, however, probe performance degrades, revealing interference between concepts. This highlights that while atomic concepts are reliably localized, composition remains a challenge, underscoring a key limitation in current TSFMs' ability to represent interacting temporal phenomena.",cs.LG,2025-11-19 10:41:02+00:00,timeseries foundation model tsfms recently emerged universal paradigm learning across diverse temporal domain however despite empirical success internal mechanism model represent fundamental timeseries concept remain poorly understood work undertake systematic investigation concept interpretability tsfms specifically examine layer encode concept ii whether concept parameter linearly recoverable iii representation evolve term concept disentanglement abstraction across model depth iv model process composition concept systematically probe question using layerwise analysis linear recoverability test representation similarity measure providing structured account tsfm semantics resulting insight show early layer mainly capture local timedomain pattern eg ar1 level shift trend deeper layer encode dispersion changetime signal spectral warping factor remaining hardest recover linearly compositional setting however probe performance degrades revealing interference concept highlight atomic concept reliably localized composition remains challenge underscoring key limitation current tsfms ability represent interacting temporal phenomenon,7,"supervised, audio"
Location--Scale Calibration for Generalized Posterior,"Shu Tamano, Yui Tomo","General Bayesian updating replaces the likelihood with a loss scaled by a learning rate, but posterior uncertainty can depend sharply on that scale. We propose a simple post-processing that aligns generalized posterior draws with their asymptotic target, yielding uncertainty quantification that is invariant to the learning rate. We prove total-variation convergence for generalized posteriors with an effective sample size, allowing sample-size-dependent priors, non-i.i.d. observations, and convex penalties under model misspecification. Within this framework, we justify and extend the open-faced sandwich adjustment (Shaby, 2014), provide general theoretical guarantees for its use within generalized Bayes, and extend it from covariance rescaling to a location--scale calibration whose draws converge in total variation to the target for any learning rate. In our empirical illustration, calibrated draws maintain stable coverage, interval width, and bias over orders of magnitude in the learning rate and closely track frequentist benchmarks, whereas uncalibrated posteriors vary markedly.",stat.ME,2025-11-19 10:37:13+00:00,general bayesian updating replaces likelihood loss scaled learning rate posterior uncertainty depend sharply scale propose simple postprocessing aligns generalized posterior draw asymptotic target yielding uncertainty quantification invariant learning rate prove totalvariation convergence generalized posterior effective sample size allowing samplesizedependent prior noniid observation convex penalty model misspecification within framework justify extend openfaced sandwich adjustment shaby 2014 provide general theoretical guarantee use within generalized bayes extend covariance rescaling locationscale calibration whose draw converge total variation target learning rate empirical illustration calibrated draw maintain stable coverage interval width bias order magnitude learning rate closely track frequentist benchmark whereas uncalibrated posterior vary markedly,2,"dynamicslearning, sgd"
What Your Features Reveal: Data-Efficient Black-Box Feature Inversion Attack for Split DNNs,"Zhihan Ren, Lijun He, Jiaxi Liang, Xinzhu Fu, Haixia Bi, Fan Li","Split DNNs enable edge devices by offloading intensive computation to a cloud server, but this paradigm exposes privacy vulnerabilities, as the intermediate features can be exploited to reconstruct the private inputs via Feature Inversion Attack (FIA). Existing FIA methods often produce limited reconstruction quality, making it difficult to assess the true extent of privacy leakage. To reveal the privacy risk of the leaked features, we introduce FIA-Flow, a black-box FIA framework that achieves high-fidelity image reconstruction from intermediate features. To exploit the semantic information within intermediate features, we design a Latent Feature Space Alignment Module (LFSAM) to bridge the semantic gap between the intermediate feature space and the latent space. Furthermore, to rectify distributional mismatch, we develop Deterministic Inversion Flow Matching (DIFM), which projects off-manifold features onto the target manifold with one-step inference. This decoupled design simplifies learning and enables effective training with few image-feature pairs. To quantify privacy leakage from a human perspective, we also propose two metrics based on a large vision-language model. Experiments show that FIA-Flow achieves more faithful and semantically aligned feature inversion across various models (AlexNet, ResNet, Swin Transformer, DINO, and YOLO11) and layers, revealing a more severe privacy threat in Split DNNs than previously recognized.",cs.CV,2025-11-19 10:30:38+00:00,split dnns enable edge device offloading intensive computation cloud server paradigm expose privacy vulnerability intermediate feature exploited reconstruct private input via feature inversion attack fia existing fia method often produce limited reconstruction quality making difficult assess true extent privacy leakage reveal privacy risk leaked feature introduce fiaflow blackbox fia framework achieves highfidelity image reconstruction intermediate feature exploit semantic information within intermediate feature design latent feature space alignment module lfsam bridge semantic gap intermediate feature space latent space furthermore rectify distributional mismatch develop deterministic inversion flow matching difm project offmanifold feature onto target manifold onestep inference decoupled design simplifies learning enables effective training imagefeature pair quantify privacy leakage human perspective also propose two metric based large visionlanguage model experiment show fiaflow achieves faithful semantically aligned feature inversion across various model alexnet resnet swin transformer dino yolo11 layer revealing severe privacy threat split dnns previously recognized,4,"forgetting, memoryintensive"
